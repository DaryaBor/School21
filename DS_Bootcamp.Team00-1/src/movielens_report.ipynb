{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отчет по функциям movielens_analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'movielens_analysis' in sys.modules:\n",
    "    del sys.modules['movielens_analysis']\n",
    "from movielens_analysis import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Класс Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154 ns ± 9.04 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit movies= Movies(\"data/movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies= Movies(\"data/movies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dist_by_release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        The method returns a dict or an OrderedDict where the keys are years and the values are counts. \n",
      "        You need to extract years from the titles. Sort it by counts descendingly.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(movies.dist_by_release.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.3 ms ± 568 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit movies.dist_by_release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2002': 311,\n",
       " '2006': 295,\n",
       " '2001': 294,\n",
       " '2007': 284,\n",
       " '2000': 283,\n",
       " '2009': 282,\n",
       " '2003': 279,\n",
       " '2004': 279,\n",
       " '2014': 278,\n",
       " '1996': 276,\n",
       " '2015': 274,\n",
       " '2005': 273,\n",
       " '2008': 269,\n",
       " '1999': 263,\n",
       " '1997': 260,\n",
       " '1995': 259,\n",
       " '1998': 258,\n",
       " '2011': 254,\n",
       " '2010': 247,\n",
       " '2013': 239,\n",
       " '1994': 237,\n",
       " '2012': 233,\n",
       " '2016': 218,\n",
       " '1993': 198,\n",
       " '1992': 167,\n",
       " '1988': 165,\n",
       " '1987': 153,\n",
       " '1990': 147,\n",
       " '1991': 147,\n",
       " '2017': 147,\n",
       " '1989': 142,\n",
       " '1986': 139,\n",
       " '1985': 126,\n",
       " '1984': 101,\n",
       " '1981': 92,\n",
       " '1980': 89,\n",
       " '1982': 87,\n",
       " '1983': 83,\n",
       " '1979': 69,\n",
       " '1977': 63,\n",
       " '1973': 59,\n",
       " '1978': 59,\n",
       " '1965': 47,\n",
       " '1971': 47,\n",
       " '1974': 45,\n",
       " '1976': 44,\n",
       " '1964': 43,\n",
       " '1967': 42,\n",
       " '1968': 42,\n",
       " '1975': 42,\n",
       " '1966': 42,\n",
       " '2018': 41,\n",
       " '1962': 40,\n",
       " '1972': 39,\n",
       " '1963': 39,\n",
       " '1959': 37,\n",
       " '1960': 37,\n",
       " '1955': 36,\n",
       " '1969': 35,\n",
       " '1961': 34,\n",
       " '1970': 33,\n",
       " '1957': 33,\n",
       " '1958': 31,\n",
       " '1953': 30,\n",
       " '1956': 30,\n",
       " '1940': 25,\n",
       " '1949': 25,\n",
       " '1954': 23,\n",
       " '1942': 23,\n",
       " '1939': 23,\n",
       " '1946': 23,\n",
       " '1951': 22,\n",
       " '1950': 21,\n",
       " '1947': 20,\n",
       " '1948': 20,\n",
       " '1941': 18,\n",
       " '1936': 18,\n",
       " '1945': 17,\n",
       " '1937': 16,\n",
       " '1952': 16,\n",
       " '1944': 16,\n",
       " '1938': 15,\n",
       " '1931': 14,\n",
       " '1935': 13,\n",
       " '1933': 12,\n",
       " '1934': 11,\n",
       " '1943': 10,\n",
       " '1932': 9,\n",
       " '1927': 7,\n",
       " '1930': 5,\n",
       " '1926': 5,\n",
       " '1924': 5,\n",
       " '1929': 4,\n",
       " '1928': 4,\n",
       " '1925': 4,\n",
       " '1923': 4,\n",
       " '1916': 4,\n",
       " '1920': 2,\n",
       " '1922': 1,\n",
       " '1919': 1,\n",
       " '1921': 1,\n",
       " '1915': 1,\n",
       " '1917': 1,\n",
       " '1902': 1,\n",
       " '1903': 1,\n",
       " '1908': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.dist_by_release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из результатов наибольшее количество фильмов было выпущено в 2002 году. А стремительный рост выпущенных фильмов начинается в 2002, что объясняется прорывом кино в различных жанрах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dist_by_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        The method returns a dict where the keys are genres and the values are counts.\n",
      "        Sort it by counts descendingly.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(movies.dist_by_genres.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.4 ms ± 1.54 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit movies.dist_by_genres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Drama': 974,\n",
       " 'Adventure': 578,\n",
       " 'Comedy': 447,\n",
       " 'Crime': 380,\n",
       " 'Horror': 261,\n",
       " 'Children': 238,\n",
       " 'Fantasy': 234,\n",
       " 'Animation': 229,\n",
       " 'Mystery': 219,\n",
       " 'Sci-Fi': 177,\n",
       " 'Romance': 127,\n",
       " 'Musical': 81,\n",
       " 'Thriller': 46,\n",
       " 'no genres listed': 34,\n",
       " 'Film-Noir': 27,\n",
       " 'Documentary': 11,\n",
       " 'War': 6,\n",
       " 'Western': 1}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.dist_by_genres()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно в большинстве фильмов жанр не указан. В указанных преобладает драма, с большим отставанием далее идут приключения и комедия. Драма часто указывается дополнительным жанром к остальным, что объясняет ее частую встречаемость."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        The method returns a dict with top-n movies where the keys are movie titles and \n",
      "        the values are the number of genres of the movie. Sort it by numbers descendingly.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(movies.most_genres.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.9 ms ± 736 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit movies.most_genres(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Patlabor: The Movie': 10,\n",
       " 'Interstate 60': 8,\n",
       " 'Pulse': 8,\n",
       " 'Robots': 8,\n",
       " 'Aqua Teen Hunger Force Colon Movie Film for Theaters': 8,\n",
       " 'Aelita: The Queen of Mars': 8}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.most_genres(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наибольшее количество жанров, которое можно получить, встречается у фильма Patlabor, судя по названию, не удивительно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The method returns a list of movies by the year\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(movies.movies_by_year.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "movies_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"\"Fog, The',\n",
       " '\"\"Howling, The',\n",
       " 'Private Benjamin',\n",
       " 'Star Wars: Episode V - The Empire Strikes Back',\n",
       " '\"\"Blues Brothers, The',\n",
       " 'Raging Bull',\n",
       " '\"\"Shining, The',\n",
       " 'Somewhere in Time',\n",
       " 'Ordinary People',\n",
       " 'Friday the 13th',\n",
       " 'Prom Night',\n",
       " 'Herbie Goes Bananas',\n",
       " 'Popeye',\n",
       " 'Atlantic City',\n",
       " '\"\"Gods Must Be Crazy, The',\n",
       " 'My Bodyguard',\n",
       " '\"\"Fiendish Plot of Dr. Fu Manchu, The',\n",
       " 'Stardust Memories',\n",
       " '\"\"Elephant Man, The',\n",
       " 'Alligator',\n",
       " 'Superman II',\n",
       " 'Airplane!',\n",
       " 'Saturn 3',\n",
       " '\"\"Blue Lagoon, The',\n",
       " 'Melvin and Howard',\n",
       " 'Kagemusha',\n",
       " 'Where the Buffalo Roam',\n",
       " 'Raise the Titanic',\n",
       " 'Caddyshack',\n",
       " 'The Idolmaker',\n",
       " 'Inferno',\n",
       " '\"\"Hollywood Knights, The',\n",
       " 'American Gigolo',\n",
       " '\"\"City of the Living Dead',\n",
       " 'Breaker Morant',\n",
       " 'Bronco Billy',\n",
       " 'Battle Beyond the Stars',\n",
       " '\"\"City of Women, The',\n",
       " 'Nine to Five',\n",
       " 'Altered States',\n",
       " 'Any Which Way You Can',\n",
       " '\"\"Awakening, The',\n",
       " '\"\"Battle Creek Brawl',\n",
       " '\"\"Big Red One, The',\n",
       " '\"\"Boogeyman, The',\n",
       " '\"\"Party, The',\n",
       " 'Brubaker',\n",
       " \"Can't Stop the Music\",\n",
       " '\"\"Changeling, The',\n",
       " \"Coal Miner's Daughter\",\n",
       " '\"\"Competition, The',\n",
       " '\"\"Last Metro, The',\n",
       " 'Dressed to Kill',\n",
       " 'Fame',\n",
       " '\"\"Final Countdown, The',\n",
       " 'Flash Gordon',\n",
       " '\"\"Stunt Man, The',\n",
       " 'Hangar 18',\n",
       " 'Hopscotch',\n",
       " 'Humanoids from the Deep',\n",
       " 'Little Darlings',\n",
       " '\"\"Long Good Friday, The',\n",
       " \"Mon oncle d'Amérique\",\n",
       " 'Motel Hell',\n",
       " '\"\"Octagon, The',\n",
       " '\"\"Oh, God! Book II',\n",
       " 'Return of the Secaucus 7',\n",
       " 'Rude Boy',\n",
       " 'Running Scared',\n",
       " 'Seems Like Old Times',\n",
       " 'Shogun Assassin',\n",
       " 'Smokey and the Bandit II',\n",
       " 'Stir Crazy',\n",
       " '\"\"Watcher in the Woods, The',\n",
       " 'Urban Cowboy',\n",
       " 'Tom Horn',\n",
       " 'The Pumaman',\n",
       " 'Without Warning',\n",
       " 'Alien Contamination',\n",
       " 'Cannibal Holocaust',\n",
       " 'Little Miss Marker',\n",
       " '\"\"Legend of Sleepy Hollow, The',\n",
       " 'Flatfoot on the Nile',\n",
       " 'Half a Loaf of Kung Fu',\n",
       " 'The Taming of the Scoundrel',\n",
       " 'The Adventures of Sherlock Holmes and Doctor Watson: King of Blackmailers',\n",
       " 'Saturn 3',\n",
       " 'Vacations in Prostokvashino',\n",
       " 'The Adventures of Sherlock Holmes and Doctor Watson: The Hunt for the Tiger']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "if 'movielens_analysis' in sys.modules:\n",
    "    del sys.modules['movielens_analysis']\n",
    "from movielens_analysis import *\n",
    "movies= Movies(\"data/movies.csv\")\n",
    "movies.movies_by_year(1980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.13.0, pytest-8.3.5, pluggy-1.5.0\n",
      "rootdir: c:\\Users\\ruber\\OneDrive\\Рабочий стол\\школа21\\DS_Bootcamp.Team00-1\\src\n",
      "collected 27 items\n",
      "\n",
      "movielens_analysis.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[31mE\u001b[0m\u001b[31mE\u001b[0m\u001b[31mE\u001b[0m\u001b[31mE\u001b[0m\u001b[31mE\u001b[0m\u001b[31mE\u001b[0m\u001b[31mE\u001b[0m\u001b[31m                        [100%]\u001b[0m\n",
      "\n",
      "=================================== ERRORS ====================================\n",
      "\u001b[31m\u001b[1m________________ ERROR at setup of TestLinks.test_init_parced _________________\u001b[0m\n",
      "\n",
      "path_to_the_file = 'data/links_parsed.csv'\n",
      "types = [<class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, ...]\n",
      "set_None = True\n",
      "\n",
      "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcsv_to_list_of_dicts\u001b[39;49;00m(path_to_the_file, types, set_None=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "        data = []\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mwith\u001b[39;49;00m \u001b[96mopen\u001b[39;49;00m(path_to_the_file) \u001b[94mas\u001b[39;49;00m file:\u001b[90m\u001b[39;49;00m\n",
      ">               text = file.read()\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:59: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <encodings.cp1251.IncrementalDecoder object at 0x000001AC44343360>\n",
      "input = b'movieId,imdbId,tmdbId,title,runtime,director,gross_worldwide,budget\\n1,0114709,862,\"Toy Story\",\"1h 21m\",\"John Lasset...d Apple\",\"1h 32m\",\"Takuya Igarashi\",2373203,None\\n193609,0101726,37891,\"Dice Rules\",\"1h 28m\",\"Jay Dubin\",637327,None\\n'\n",
      "final = True\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdecode\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, \u001b[96minput\u001b[39;49;00m, final=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m codecs.charmap_decode(\u001b[96minput\u001b[39;49;00m,\u001b[96mself\u001b[39;49;00m.errors,decoding_table)[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 564433: character maps to <undefined>\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\ruber\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\encodings\\cp1251.py\u001b[0m:23: UnicodeDecodeError\n",
      "\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\n",
      "self = <movielens_analysis.TestLinks object at 0x000001AC43D2A120>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mmodule\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mlinks_parsed\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m Links(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata/links_parsed.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, parsed=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:804: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:225: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.data = CSVReader.csv_to_list_of_dicts(path_to_the_file,\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_to_the_file = 'data/links_parsed.csv'\n",
      "types = [<class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, ...]\n",
      "set_None = True\n",
      "\n",
      "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcsv_to_list_of_dicts\u001b[39;49;00m(path_to_the_file, types, set_None=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "        data = []\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mwith\u001b[39;49;00m \u001b[96mopen\u001b[39;49;00m(path_to_the_file) \u001b[94mas\u001b[39;49;00m file:\u001b[90m\u001b[39;49;00m\n",
      "                text = file.read()\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m text[-\u001b[94m1\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    text = text[:-\u001b[94m1\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mexcept\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mНеверное имя файла: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_to_the_file\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           ValueError: Неверное имя файла: data/links_parsed.csv\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:63: ValueError\n",
      "\u001b[31m\u001b[1m__________________ ERROR at setup of TestLinks.test_get_imdb __________________\u001b[0m\n",
      "\n",
      "path_to_the_file = 'data/links_parsed.csv'\n",
      "types = [<class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, ...]\n",
      "set_None = True\n",
      "\n",
      "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcsv_to_list_of_dicts\u001b[39;49;00m(path_to_the_file, types, set_None=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "        data = []\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mwith\u001b[39;49;00m \u001b[96mopen\u001b[39;49;00m(path_to_the_file) \u001b[94mas\u001b[39;49;00m file:\u001b[90m\u001b[39;49;00m\n",
      ">               text = file.read()\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:59: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <encodings.cp1251.IncrementalDecoder object at 0x000001AC44343360>\n",
      "input = b'movieId,imdbId,tmdbId,title,runtime,director,gross_worldwide,budget\\n1,0114709,862,\"Toy Story\",\"1h 21m\",\"John Lasset...d Apple\",\"1h 32m\",\"Takuya Igarashi\",2373203,None\\n193609,0101726,37891,\"Dice Rules\",\"1h 28m\",\"Jay Dubin\",637327,None\\n'\n",
      "final = True\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdecode\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, \u001b[96minput\u001b[39;49;00m, final=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m codecs.charmap_decode(\u001b[96minput\u001b[39;49;00m,\u001b[96mself\u001b[39;49;00m.errors,decoding_table)[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 564433: character maps to <undefined>\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\ruber\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\encodings\\cp1251.py\u001b[0m:23: UnicodeDecodeError\n",
      "\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\n",
      "self = <movielens_analysis.TestLinks object at 0x000001AC43D2A120>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mmodule\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mlinks_parsed\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m Links(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata/links_parsed.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, parsed=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:804: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:225: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.data = CSVReader.csv_to_list_of_dicts(path_to_the_file,\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_to_the_file = 'data/links_parsed.csv'\n",
      "types = [<class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, ...]\n",
      "set_None = True\n",
      "\n",
      "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcsv_to_list_of_dicts\u001b[39;49;00m(path_to_the_file, types, set_None=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "        data = []\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mwith\u001b[39;49;00m \u001b[96mopen\u001b[39;49;00m(path_to_the_file) \u001b[94mas\u001b[39;49;00m file:\u001b[90m\u001b[39;49;00m\n",
      "                text = file.read()\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m text[-\u001b[94m1\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    text = text[:-\u001b[94m1\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mexcept\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mНеверное имя файла: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_to_the_file\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           ValueError: Неверное имя файла: data/links_parsed.csv\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:63: ValueError\n",
      "\u001b[31m\u001b[1m_______________ ERROR at setup of TestLinks.test_top_directors ________________\u001b[0m\n",
      "\n",
      "path_to_the_file = 'data/links_parsed.csv'\n",
      "types = [<class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, ...]\n",
      "set_None = True\n",
      "\n",
      "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcsv_to_list_of_dicts\u001b[39;49;00m(path_to_the_file, types, set_None=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "        data = []\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mwith\u001b[39;49;00m \u001b[96mopen\u001b[39;49;00m(path_to_the_file) \u001b[94mas\u001b[39;49;00m file:\u001b[90m\u001b[39;49;00m\n",
      ">               text = file.read()\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:59: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <encodings.cp1251.IncrementalDecoder object at 0x000001AC44343360>\n",
      "input = b'movieId,imdbId,tmdbId,title,runtime,director,gross_worldwide,budget\\n1,0114709,862,\"Toy Story\",\"1h 21m\",\"John Lasset...d Apple\",\"1h 32m\",\"Takuya Igarashi\",2373203,None\\n193609,0101726,37891,\"Dice Rules\",\"1h 28m\",\"Jay Dubin\",637327,None\\n'\n",
      "final = True\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdecode\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, \u001b[96minput\u001b[39;49;00m, final=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m codecs.charmap_decode(\u001b[96minput\u001b[39;49;00m,\u001b[96mself\u001b[39;49;00m.errors,decoding_table)[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 564433: character maps to <undefined>\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\ruber\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\encodings\\cp1251.py\u001b[0m:23: UnicodeDecodeError\n",
      "\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\n",
      "self = <movielens_analysis.TestLinks object at 0x000001AC43D2A120>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mmodule\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mlinks_parsed\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m Links(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata/links_parsed.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, parsed=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:804: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:225: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.data = CSVReader.csv_to_list_of_dicts(path_to_the_file,\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_to_the_file = 'data/links_parsed.csv'\n",
      "types = [<class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, ...]\n",
      "set_None = True\n",
      "\n",
      "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcsv_to_list_of_dicts\u001b[39;49;00m(path_to_the_file, types, set_None=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "        data = []\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mwith\u001b[39;49;00m \u001b[96mopen\u001b[39;49;00m(path_to_the_file) \u001b[94mas\u001b[39;49;00m file:\u001b[90m\u001b[39;49;00m\n",
      "                text = file.read()\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m text[-\u001b[94m1\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    text = text[:-\u001b[94m1\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mexcept\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mНеверное имя файла: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_to_the_file\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           ValueError: Неверное имя файла: data/links_parsed.csv\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:63: ValueError\n",
      "\u001b[31m\u001b[1m_______________ ERROR at setup of TestLinks.test_most_expensive _______________\u001b[0m\n",
      "\n",
      "path_to_the_file = 'data/links_parsed.csv'\n",
      "types = [<class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, ...]\n",
      "set_None = True\n",
      "\n",
      "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcsv_to_list_of_dicts\u001b[39;49;00m(path_to_the_file, types, set_None=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "        data = []\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mwith\u001b[39;49;00m \u001b[96mopen\u001b[39;49;00m(path_to_the_file) \u001b[94mas\u001b[39;49;00m file:\u001b[90m\u001b[39;49;00m\n",
      ">               text = file.read()\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:59: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <encodings.cp1251.IncrementalDecoder object at 0x000001AC44343360>\n",
      "input = b'movieId,imdbId,tmdbId,title,runtime,director,gross_worldwide,budget\\n1,0114709,862,\"Toy Story\",\"1h 21m\",\"John Lasset...d Apple\",\"1h 32m\",\"Takuya Igarashi\",2373203,None\\n193609,0101726,37891,\"Dice Rules\",\"1h 28m\",\"Jay Dubin\",637327,None\\n'\n",
      "final = True\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdecode\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, \u001b[96minput\u001b[39;49;00m, final=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m codecs.charmap_decode(\u001b[96minput\u001b[39;49;00m,\u001b[96mself\u001b[39;49;00m.errors,decoding_table)[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 564433: character maps to <undefined>\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\ruber\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\encodings\\cp1251.py\u001b[0m:23: UnicodeDecodeError\n",
      "\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\n",
      "self = <movielens_analysis.TestLinks object at 0x000001AC43D2A120>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mmodule\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mlinks_parsed\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m Links(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata/links_parsed.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, parsed=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:804: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:225: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.data = CSVReader.csv_to_list_of_dicts(path_to_the_file,\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_to_the_file = 'data/links_parsed.csv'\n",
      "types = [<class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, ...]\n",
      "set_None = True\n",
      "\n",
      "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcsv_to_list_of_dicts\u001b[39;49;00m(path_to_the_file, types, set_None=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "        data = []\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mwith\u001b[39;49;00m \u001b[96mopen\u001b[39;49;00m(path_to_the_file) \u001b[94mas\u001b[39;49;00m file:\u001b[90m\u001b[39;49;00m\n",
      "                text = file.read()\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m text[-\u001b[94m1\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    text = text[:-\u001b[94m1\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mexcept\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mНеверное имя файла: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_to_the_file\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           ValueError: Неверное имя файла: data/links_parsed.csv\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:63: ValueError\n",
      "\u001b[31m\u001b[1m______________ ERROR at setup of TestLinks.test_most_profitable _______________\u001b[0m\n",
      "\n",
      "path_to_the_file = 'data/links_parsed.csv'\n",
      "types = [<class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, ...]\n",
      "set_None = True\n",
      "\n",
      "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcsv_to_list_of_dicts\u001b[39;49;00m(path_to_the_file, types, set_None=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "        data = []\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mwith\u001b[39;49;00m \u001b[96mopen\u001b[39;49;00m(path_to_the_file) \u001b[94mas\u001b[39;49;00m file:\u001b[90m\u001b[39;49;00m\n",
      ">               text = file.read()\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:59: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <encodings.cp1251.IncrementalDecoder object at 0x000001AC44343360>\n",
      "input = b'movieId,imdbId,tmdbId,title,runtime,director,gross_worldwide,budget\\n1,0114709,862,\"Toy Story\",\"1h 21m\",\"John Lasset...d Apple\",\"1h 32m\",\"Takuya Igarashi\",2373203,None\\n193609,0101726,37891,\"Dice Rules\",\"1h 28m\",\"Jay Dubin\",637327,None\\n'\n",
      "final = True\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdecode\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, \u001b[96minput\u001b[39;49;00m, final=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m codecs.charmap_decode(\u001b[96minput\u001b[39;49;00m,\u001b[96mself\u001b[39;49;00m.errors,decoding_table)[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 564433: character maps to <undefined>\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\ruber\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\encodings\\cp1251.py\u001b[0m:23: UnicodeDecodeError\n",
      "\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\n",
      "self = <movielens_analysis.TestLinks object at 0x000001AC43D2A120>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mmodule\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mlinks_parsed\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m Links(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata/links_parsed.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, parsed=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:804: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:225: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.data = CSVReader.csv_to_list_of_dicts(path_to_the_file,\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_to_the_file = 'data/links_parsed.csv'\n",
      "types = [<class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, ...]\n",
      "set_None = True\n",
      "\n",
      "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcsv_to_list_of_dicts\u001b[39;49;00m(path_to_the_file, types, set_None=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "        data = []\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mwith\u001b[39;49;00m \u001b[96mopen\u001b[39;49;00m(path_to_the_file) \u001b[94mas\u001b[39;49;00m file:\u001b[90m\u001b[39;49;00m\n",
      "                text = file.read()\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m text[-\u001b[94m1\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    text = text[:-\u001b[94m1\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mexcept\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mНеверное имя файла: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_to_the_file\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           ValueError: Неверное имя файла: data/links_parsed.csv\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:63: ValueError\n",
      "\u001b[31m\u001b[1m__________________ ERROR at setup of TestLinks.test_longest ___________________\u001b[0m\n",
      "\n",
      "path_to_the_file = 'data/links_parsed.csv'\n",
      "types = [<class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, ...]\n",
      "set_None = True\n",
      "\n",
      "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcsv_to_list_of_dicts\u001b[39;49;00m(path_to_the_file, types, set_None=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "        data = []\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mwith\u001b[39;49;00m \u001b[96mopen\u001b[39;49;00m(path_to_the_file) \u001b[94mas\u001b[39;49;00m file:\u001b[90m\u001b[39;49;00m\n",
      ">               text = file.read()\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:59: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <encodings.cp1251.IncrementalDecoder object at 0x000001AC44343360>\n",
      "input = b'movieId,imdbId,tmdbId,title,runtime,director,gross_worldwide,budget\\n1,0114709,862,\"Toy Story\",\"1h 21m\",\"John Lasset...d Apple\",\"1h 32m\",\"Takuya Igarashi\",2373203,None\\n193609,0101726,37891,\"Dice Rules\",\"1h 28m\",\"Jay Dubin\",637327,None\\n'\n",
      "final = True\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdecode\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, \u001b[96minput\u001b[39;49;00m, final=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m codecs.charmap_decode(\u001b[96minput\u001b[39;49;00m,\u001b[96mself\u001b[39;49;00m.errors,decoding_table)[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 564433: character maps to <undefined>\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\ruber\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\encodings\\cp1251.py\u001b[0m:23: UnicodeDecodeError\n",
      "\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\n",
      "self = <movielens_analysis.TestLinks object at 0x000001AC43D2A120>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mmodule\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mlinks_parsed\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m Links(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata/links_parsed.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, parsed=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:804: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:225: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.data = CSVReader.csv_to_list_of_dicts(path_to_the_file,\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_to_the_file = 'data/links_parsed.csv'\n",
      "types = [<class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, ...]\n",
      "set_None = True\n",
      "\n",
      "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcsv_to_list_of_dicts\u001b[39;49;00m(path_to_the_file, types, set_None=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "        data = []\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mwith\u001b[39;49;00m \u001b[96mopen\u001b[39;49;00m(path_to_the_file) \u001b[94mas\u001b[39;49;00m file:\u001b[90m\u001b[39;49;00m\n",
      "                text = file.read()\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m text[-\u001b[94m1\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    text = text[:-\u001b[94m1\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mexcept\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mНеверное имя файла: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_to_the_file\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           ValueError: Неверное имя файла: data/links_parsed.csv\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:63: ValueError\n",
      "\u001b[31m\u001b[1m____________ ERROR at setup of TestLinks.test_top_cost_per_minute _____________\u001b[0m\n",
      "\n",
      "path_to_the_file = 'data/links_parsed.csv'\n",
      "types = [<class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, ...]\n",
      "set_None = True\n",
      "\n",
      "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcsv_to_list_of_dicts\u001b[39;49;00m(path_to_the_file, types, set_None=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "        data = []\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mwith\u001b[39;49;00m \u001b[96mopen\u001b[39;49;00m(path_to_the_file) \u001b[94mas\u001b[39;49;00m file:\u001b[90m\u001b[39;49;00m\n",
      ">               text = file.read()\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:59: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <encodings.cp1251.IncrementalDecoder object at 0x000001AC44343360>\n",
      "input = b'movieId,imdbId,tmdbId,title,runtime,director,gross_worldwide,budget\\n1,0114709,862,\"Toy Story\",\"1h 21m\",\"John Lasset...d Apple\",\"1h 32m\",\"Takuya Igarashi\",2373203,None\\n193609,0101726,37891,\"Dice Rules\",\"1h 28m\",\"Jay Dubin\",637327,None\\n'\n",
      "final = True\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdecode\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, \u001b[96minput\u001b[39;49;00m, final=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m codecs.charmap_decode(\u001b[96minput\u001b[39;49;00m,\u001b[96mself\u001b[39;49;00m.errors,decoding_table)[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 564433: character maps to <undefined>\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\ruber\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\encodings\\cp1251.py\u001b[0m:23: UnicodeDecodeError\n",
      "\n",
      "\u001b[33mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
      "\n",
      "self = <movielens_analysis.TestLinks object at 0x000001AC43D2A120>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mmodule\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mlinks_parsed\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m Links(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata/links_parsed.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, parsed=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:804: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:225: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.data = CSVReader.csv_to_list_of_dicts(path_to_the_file,\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "path_to_the_file = 'data/links_parsed.csv'\n",
      "types = [<class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>, ...]\n",
      "set_None = True\n",
      "\n",
      "    \u001b[0m\u001b[37m@staticmethod\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mcsv_to_list_of_dicts\u001b[39;49;00m(path_to_the_file, types, set_None=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "        data = []\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mwith\u001b[39;49;00m \u001b[96mopen\u001b[39;49;00m(path_to_the_file) \u001b[94mas\u001b[39;49;00m file:\u001b[90m\u001b[39;49;00m\n",
      "                text = file.read()\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m text[-\u001b[94m1\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    text = text[:-\u001b[94m1\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mexcept\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mНеверное имя файла: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mpath_to_the_file\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           ValueError: Неверное имя файла: data/links_parsed.csv\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:63: ValueError\n",
      "================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_____________________ TestMovies.test_movies_by_the_year ______________________\u001b[0m\n",
      "\n",
      "self = <movielens_analysis.TestMovies object at 0x000001AC43D7C510>\n",
      "movies_obj = <movielens_analysis.Movies object at 0x000001AC43D7C8A0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_movies_by_the_year\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m,movies_obj):\u001b[90m\u001b[39;49;00m\n",
      "        year=\u001b[94m2005\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m \u001b[96mtype\u001b[39;49;00m(movies_obj.movies_by_the_year(year))==\u001b[96mlist\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AttributeError: 'Movies' object has no attribute 'movies_by_the_year'. Did you mean: 'movies_by_year'?\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:794: AttributeError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m movielens_analysis.py::\u001b[1mTestMovies::test_movies_by_the_year\u001b[0m - AttributeError: 'Movies' object has no attribute 'movies_by_the_year'. Did ...\n",
      "\u001b[31mERROR\u001b[0m movielens_analysis.py::\u001b[1mTestLinks::test_init_parced\u001b[0m - ValueError: Неверное имя файла: data/links_parsed.csv\n",
      "\u001b[31mERROR\u001b[0m movielens_analysis.py::\u001b[1mTestLinks::test_get_imdb\u001b[0m - ValueError: Неверное имя файла: data/links_parsed.csv\n",
      "\u001b[31mERROR\u001b[0m movielens_analysis.py::\u001b[1mTestLinks::test_top_directors\u001b[0m - ValueError: Неверное имя файла: data/links_parsed.csv\n",
      "\u001b[31mERROR\u001b[0m movielens_analysis.py::\u001b[1mTestLinks::test_most_expensive\u001b[0m - ValueError: Неверное имя файла: data/links_parsed.csv\n",
      "\u001b[31mERROR\u001b[0m movielens_analysis.py::\u001b[1mTestLinks::test_most_profitable\u001b[0m - ValueError: Неверное имя файла: data/links_parsed.csv\n",
      "\u001b[31mERROR\u001b[0m movielens_analysis.py::\u001b[1mTestLinks::test_longest\u001b[0m - ValueError: Неверное имя файла: data/links_parsed.csv\n",
      "\u001b[31mERROR\u001b[0m movielens_analysis.py::\u001b[1mTestLinks::test_top_cost_per_minute\u001b[0m - ValueError: Неверное имя файла: data/links_parsed.csv\n",
      "\u001b[31m=================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m19 passed\u001b[0m, \u001b[31m\u001b[1m7 errors\u001b[0m\u001b[31m in 7.48s\u001b[0m\u001b[31m ====================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest movielens_analysis.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.67 ms ± 268 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit tags= Tags(\"data/tags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags= Tags(\"data/tags.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        The method returns top-n tags with most words inside. It is a dict \n",
      "        where the keys are tags and the values are the number of words inside the tag.\n",
      "        Drop the duplicates. Sort it by numbers descendingly.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(tags.most_words.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.77 ms ± 372 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit tags.most_words(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'villain nonexistent or not needed for good story': 8,\n",
       " '06 Oscar Nominated Best Movie - Animation': 7,\n",
       " 'It was melodramatic and kind of dumb': 7,\n",
       " 'Oscar (Best Music - Original Score)': 6,\n",
       " 'stop using useless characters for filler': 6,\n",
       " 'Oscar (Best Effects - Visual Effects)': 6,\n",
       " 'Everything you want is here': 5,\n",
       " 'based on a true story': 5,\n",
       " 'based on a TV show': 5,\n",
       " 'start of a beautiful friendship': 5,\n",
       " 'rich guy - poor girl': 5,\n",
       " 'Academy award (Best Supporting Actress)': 5,\n",
       " 'a dingo ate my baby': 5,\n",
       " 'stop looking at me swan': 5,\n",
       " 'GIVE ME BACK MY SON!': 5,\n",
       " 'stupid is as stupid does': 5,\n",
       " 'r:disturbing violent content including rape': 5,\n",
       " 'heroine in tight suit': 4,\n",
       " 'lord of the rings': 4}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.most_words(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Большинство слов в тегах имеют теги с рандомными рассуждениями пользователей на 3 страницы и 5 абзацев на норвежском языке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        The method returns top-n longest tags in terms of the number of characters.\n",
      "        It is a list of the tags. Drop the duplicates. Sort it by numbers descendingly.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(tags.longest.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.03 ms ± 197 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit tags.longest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the catholic church is the most corrupt organization in history',\n",
       " 'villain nonexistent or not needed for good story',\n",
       " 'r:disturbing violent content including rape',\n",
       " '06 Oscar Nominated Best Movie - Animation',\n",
       " 'stop using useless characters for filler',\n",
       " 'Academy award (Best Supporting Actress)',\n",
       " 'Oscar (Best Effects - Visual Effects)',\n",
       " 'It was melodramatic and kind of dumb',\n",
       " 'r:sustained strong stylized violence']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.longest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самые длинные теги это легендарные комментарии к фильму от норвежцев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most_words_and_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        The method returns the intersection between top-n tags with most words inside and \n",
      "        top-n longest tags in terms of the number of characters.\n",
      "        Drop the duplicates. It is a list of the tags.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(tags.most_words_and_longest.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.3 ms ± 504 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit tags.most_words_and_longest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['06 Oscar Nominated Best Movie - Animation',\n",
       " 'It was melodramatic and kind of dumb',\n",
       " 'villain nonexistent or not needed for good story',\n",
       " 'Oscar (Best Effects - Visual Effects)',\n",
       " 'stop using useless characters for filler']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.most_words_and_longest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пересечение самых длинных комментариев и самых длинных тегов по словам это норвежские комментарии!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        The method returns the most popular tags. \n",
      "        It is a dict where the keys are tags and the values are the counts.\n",
      "        Drop the duplicates. Sort it by counts descendingly.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(tags.most_popular.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490 μs ± 31.2 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit tags.most_popular(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'In Netflix queue': 131,\n",
       " 'atmospheric': 36,\n",
       " 'superhero': 24,\n",
       " 'thought-provoking': 24,\n",
       " 'funny': 23,\n",
       " 'Disney': 23,\n",
       " 'surreal': 23,\n",
       " 'religion': 22,\n",
       " 'sci-fi': 21,\n",
       " 'dark comedy': 21}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.most_popular(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наиболее популярным тегом является наличие Sciens-Fiction в фильме. Далее по популярности наличие в фильме атмосферы, действия, комедии, сюрриализма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tags.with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        The method returns all unique tags that include the word given as the argument.\n",
      "        Drop the duplicates. It is a list of the tags. Sort it by tag names alphabetically.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(tags.tags_with.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426 μs ± 17 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit tags.tags_with('marvel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Marvel', 'marvel']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.tags_with('marvel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Класс Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В классе есть два внутренних класса: Movies и Users. Класс movies служит для анализа связанного с фильмами, а users - связанного с пользвателями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391 ms ± 17 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit Ratings(\"data/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.6 ms ± 3.65 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit Ratings.Movies(ratings.data, \"data/movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197 ns ± 4.97 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit Ratings.Users(ratings.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = Ratings(\"data/ratings.csv\")\n",
    "movies = Ratings.Movies(ratings.data, \"data/movies.csv\")\n",
    "users = Ratings.Users(ratings.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим все функции класса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dist_by_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            The method returns a dict where the keys are ratings and the values are counts.\n",
      "         Sort it by ratings ascendingly.\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(movies.dist_by_rating.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.3 ms ± 539 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit movies.dist_by_rating()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.5: 1370,\n",
       " 1.0: 2811,\n",
       " 1.5: 1791,\n",
       " 2.0: 7551,\n",
       " 2.5: 5550,\n",
       " 3.0: 20047,\n",
       " 3.5: 13136,\n",
       " 4.0: 26818,\n",
       " 4.5: 8551,\n",
       " 5.0: 13211}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.dist_by_rating()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в примере можем видеть, что люди чаще всего ставят положительные рейтинги"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dist_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            The method returns a dict where the keys are years and the values are counts. \n",
      "            Sort it by years ascendingly. You need to extract years from timestamps.\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(movies.dist_by_year.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.1 ms ± 497 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit movies.dist_by_year()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1996: 6040,\n",
       " 1997: 1916,\n",
       " 1998: 507,\n",
       " 1999: 2439,\n",
       " 2000: 10061,\n",
       " 2001: 3922,\n",
       " 2002: 3478,\n",
       " 2003: 4014,\n",
       " 2004: 3279,\n",
       " 2005: 5813,\n",
       " 2006: 4059,\n",
       " 2007: 7114,\n",
       " 2008: 4351,\n",
       " 2009: 4158,\n",
       " 2010: 2300,\n",
       " 2011: 1690,\n",
       " 2012: 4657,\n",
       " 2013: 1664,\n",
       " 2014: 1439,\n",
       " 2015: 6616,\n",
       " 2016: 6702,\n",
       " 2017: 8199,\n",
       " 2018: 6418}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.dist_by_year()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ДОП: dist_by_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            The method returns a dict where the keys are years and the values are counts. \n",
      "            Sort it by years ascendingly. You need to extract years from timestamps.\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(movies.dist_by_year.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.24 ms ± 368 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit movies.dist_by_month()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 8612,\n",
       " 2: 7693,\n",
       " 3: 8784,\n",
       " 4: 7831,\n",
       " 5: 10854,\n",
       " 6: 8847,\n",
       " 7: 6931,\n",
       " 8: 8945,\n",
       " 9: 8672,\n",
       " 10: 7150,\n",
       " 11: 9675,\n",
       " 12: 6842}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.dist_by_month()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top_by_num_of_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            The method returns top-n movies by the number of ratings. \n",
      "            It is a dict where the keys are movie titles and the values are numbers.\n",
      "     Sort it by numbers descendingly.\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(movies.top_by_num_of_ratings.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.64 s ± 145 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit movies.top_by_num_of_ratings(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Forrest Gump (1994)': 329,\n",
       " 'Shawshank Redemption, The (1994)': 317,\n",
       " 'Pulp Fiction (1994)': 307,\n",
       " 'Silence of the Lambs, The (1991)': 279,\n",
       " 'Matrix, The (1999)': 278,\n",
       " 'Star Wars: Episode IV - A New Hope (1977)': 251,\n",
       " 'Jurassic Park (1993)': 238,\n",
       " 'Braveheart (1995)': 237,\n",
       " 'Terminator 2: Judgment Day (1991)': 224,\n",
       " \"Schindler's List (1993)\": 220}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.top_by_num_of_ratings(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top_by_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            The method returns top-n movies by the average or median of the ratings.\n",
      "            It is a dict where the keys are movie titles and the values are metric values.\n",
      "            Sort it by metric descendingly.\n",
      "            The values should be rounded to 2 decimals.\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(movies.top_by_ratings.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.8 ms ± 3.44 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit movies.top_by_ratings(10, 'average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The Jinx: The Life and Deaths of Robert Durst (2015)': 5.0,\n",
       " 'Galaxy of Terror (Quest) (1981)': 5.0,\n",
       " 'Alien Contamination (1980)': 5.0,\n",
       " \"I'm the One That I Want (2000)\": 5.0,\n",
       " 'Lesson Faust (1994)': 5.0,\n",
       " 'Assignment, The (1997)': 5.0,\n",
       " 'Mephisto (1981)': 5.0,\n",
       " 'Black Mirror': 5.0,\n",
       " 'Dylan Moran: Monster (2004)': 5.0,\n",
       " 'Bill Hicks: Revelations (1993)': 5.0}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.top_by_ratings(10, 'average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.3 ms ± 5.11 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit movies.top_by_ratings(10, 'median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The Jinx: The Life and Deaths of Robert Durst (2015)': 5.0,\n",
       " 'Galaxy of Terror (Quest) (1981)': 5.0,\n",
       " 'Alien Contamination (1980)': 5.0,\n",
       " 'Troll 2 (1990)': 5.0,\n",
       " \"I'm the One That I Want (2000)\": 5.0,\n",
       " 'Chorus Line, A (1985)': 5.0,\n",
       " \"Guess Who's Coming to Dinner (1967)\": 5.0,\n",
       " 'Children of the Corn IV: The Gathering (1996)': 5.0,\n",
       " 'Band of Brothers (2001)': 5.0,\n",
       " 'Lesson Faust (1994)': 5.0}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.top_by_ratings(10, 'median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top_controversial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            The method returns top-n movies by the variance of the ratings.\n",
      "            It is a dict where the keys are movie titles and the values are the variances.\n",
      "          Sort it by variance descendingly.\n",
      "            The values should be rounded to 2 decimals.\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "print(movies.top_controversial.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.4 ms ± 3.54 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit movies.top_controversial(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"Ivan's Childhood (a.k.a. My Name is Ivan) (Ivanovo detstvo) (1962)\": 5.06,\n",
       " 'Fanny and Alexander (Fanny och Alexander) (1982)': 5.06,\n",
       " 'Troll 2 (1990)': 4.5,\n",
       " 'Lassie (1994)': 4.0,\n",
       " 'Zed & Two Noughts, A (1985)': 4.0,\n",
       " 'Kwaidan (Kaidan) (1964)': 4.0,\n",
       " 'Emma (2009)': 4.0,\n",
       " 'Play Time (a.k.a. Playtime) (1967)': 3.72,\n",
       " 'Room, The (2003)': 3.56,\n",
       " 'Peeping Tom (1960)': 3.5}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.top_controversial(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distribution_by_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returns the distribution of users by the number of ratings made by them.\n"
     ]
    }
   ],
   "source": [
    "print(users.distribution_by_number.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.06 ms ± 207 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit users.distribution_by_number()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{414: 2698,\n",
       " 599: 2478,\n",
       " 474: 2108,\n",
       " 448: 1864,\n",
       " 274: 1346,\n",
       " 610: 1302,\n",
       " 68: 1260,\n",
       " 380: 1218,\n",
       " 606: 1115,\n",
       " 288: 1055,\n",
       " 249: 1046,\n",
       " 387: 1027,\n",
       " 182: 977,\n",
       " 307: 975,\n",
       " 603: 943,\n",
       " 298: 939,\n",
       " 177: 904,\n",
       " 318: 879,\n",
       " 232: 862,\n",
       " 480: 836,\n",
       " 608: 831,\n",
       " 600: 763,\n",
       " 483: 728,\n",
       " 590: 728,\n",
       " 105: 722,\n",
       " 19: 703,\n",
       " 305: 677,\n",
       " 489: 648,\n",
       " 111: 646,\n",
       " 438: 635,\n",
       " 217: 613,\n",
       " 140: 608,\n",
       " 477: 600,\n",
       " 555: 578,\n",
       " 91: 575,\n",
       " 28: 570,\n",
       " 219: 528,\n",
       " 534: 520,\n",
       " 89: 518,\n",
       " 64: 517,\n",
       " 226: 507,\n",
       " 561: 505,\n",
       " 18: 502,\n",
       " 525: 500,\n",
       " 57: 476,\n",
       " 381: 474,\n",
       " 368: 469,\n",
       " 509: 467,\n",
       " 469: 465,\n",
       " 560: 458,\n",
       " 462: 455,\n",
       " 292: 446,\n",
       " 21: 443,\n",
       " 597: 443,\n",
       " 42: 440,\n",
       " 160: 437,\n",
       " 294: 437,\n",
       " 580: 436,\n",
       " 596: 411,\n",
       " 202: 403,\n",
       " 275: 403,\n",
       " 517: 400,\n",
       " 45: 399,\n",
       " 156: 398,\n",
       " 514: 397,\n",
       " 391: 386,\n",
       " 567: 385,\n",
       " 357: 383,\n",
       " 103: 377,\n",
       " 339: 371,\n",
       " 62: 366,\n",
       " 199: 363,\n",
       " 125: 360,\n",
       " 51: 359,\n",
       " 132: 347,\n",
       " 66: 345,\n",
       " 313: 340,\n",
       " 200: 334,\n",
       " 221: 331,\n",
       " 6: 314,\n",
       " 453: 311,\n",
       " 50: 310,\n",
       " 425: 306,\n",
       " 428: 300,\n",
       " 573: 299,\n",
       " 352: 294,\n",
       " 84: 293,\n",
       " 122: 292,\n",
       " 382: 291,\n",
       " 356: 289,\n",
       " 135: 279,\n",
       " 239: 279,\n",
       " 365: 277,\n",
       " 484: 275,\n",
       " 104: 273,\n",
       " 63: 271,\n",
       " 325: 270,\n",
       " 169: 269,\n",
       " 290: 267,\n",
       " 332: 267,\n",
       " 495: 265,\n",
       " 432: 260,\n",
       " 187: 258,\n",
       " 328: 255,\n",
       " 222: 250,\n",
       " 212: 248,\n",
       " 330: 247,\n",
       " 20: 242,\n",
       " 282: 237,\n",
       " 372: 236,\n",
       " 434: 233,\n",
       " 1: 232,\n",
       " 594: 232,\n",
       " 562: 231,\n",
       " 198: 230,\n",
       " 82: 227,\n",
       " 186: 226,\n",
       " 354: 226,\n",
       " 312: 223,\n",
       " 605: 221,\n",
       " 41: 217,\n",
       " 4: 216,\n",
       " 304: 216,\n",
       " 119: 215,\n",
       " 563: 213,\n",
       " 73: 210,\n",
       " 263: 210,\n",
       " 586: 208,\n",
       " 220: 207,\n",
       " 246: 204,\n",
       " 234: 202,\n",
       " 452: 202,\n",
       " 385: 201,\n",
       " 522: 200,\n",
       " 280: 196,\n",
       " 139: 194,\n",
       " 570: 191,\n",
       " 166: 190,\n",
       " 317: 189,\n",
       " 552: 188,\n",
       " 195: 187,\n",
       " 607: 187,\n",
       " 520: 186,\n",
       " 367: 185,\n",
       " 479: 181,\n",
       " 266: 180,\n",
       " 153: 179,\n",
       " 74: 177,\n",
       " 279: 176,\n",
       " 256: 174,\n",
       " 167: 173,\n",
       " 95: 168,\n",
       " 141: 168,\n",
       " 331: 168,\n",
       " 80: 167,\n",
       " 410: 167,\n",
       " 527: 167,\n",
       " 117: 165,\n",
       " 587: 165,\n",
       " 216: 164,\n",
       " 346: 164,\n",
       " 265: 163,\n",
       " 577: 161,\n",
       " 564: 157,\n",
       " 33: 156,\n",
       " 419: 155,\n",
       " 475: 155,\n",
       " 572: 155,\n",
       " 334: 154,\n",
       " 7: 152,\n",
       " 260: 152,\n",
       " 287: 152,\n",
       " 326: 152,\n",
       " 113: 150,\n",
       " 233: 150,\n",
       " 247: 150,\n",
       " 100: 148,\n",
       " 137: 141,\n",
       " 351: 141,\n",
       " 408: 141,\n",
       " 420: 141,\n",
       " 10: 140,\n",
       " 47: 140,\n",
       " 129: 140,\n",
       " 559: 140,\n",
       " 230: 139,\n",
       " 210: 138,\n",
       " 424: 138,\n",
       " 464: 138,\n",
       " 15: 135,\n",
       " 27: 135,\n",
       " 602: 135,\n",
       " 184: 134,\n",
       " 376: 133,\n",
       " 377: 131,\n",
       " 524: 131,\n",
       " 52: 130,\n",
       " 268: 129,\n",
       " 369: 129,\n",
       " 144: 128,\n",
       " 240: 128,\n",
       " 314: 128,\n",
       " 482: 128,\n",
       " 109: 127,\n",
       " 254: 127,\n",
       " 411: 127,\n",
       " 409: 126,\n",
       " 393: 123,\n",
       " 551: 123,\n",
       " 437: 122,\n",
       " 23: 121,\n",
       " 492: 121,\n",
       " 405: 120,\n",
       " 22: 119,\n",
       " 76: 119,\n",
       " 83: 118,\n",
       " 181: 118,\n",
       " 308: 115,\n",
       " 465: 115,\n",
       " 43: 114,\n",
       " 301: 114,\n",
       " 466: 113,\n",
       " 490: 113,\n",
       " 542: 113,\n",
       " 58: 112,\n",
       " 115: 112,\n",
       " 306: 112,\n",
       " 571: 112,\n",
       " 136: 111,\n",
       " 488: 111,\n",
       " 24: 110,\n",
       " 201: 110,\n",
       " 362: 109,\n",
       " 510: 108,\n",
       " 59: 107,\n",
       " 322: 107,\n",
       " 286: 106,\n",
       " 436: 106,\n",
       " 17: 105,\n",
       " 40: 103,\n",
       " 309: 103,\n",
       " 593: 103,\n",
       " 32: 102,\n",
       " 412: 102,\n",
       " 601: 101,\n",
       " 39: 100,\n",
       " 373: 100,\n",
       " 604: 100,\n",
       " 16: 98,\n",
       " 215: 98,\n",
       " 323: 98,\n",
       " 93: 97,\n",
       " 159: 97,\n",
       " 361: 97,\n",
       " 503: 95,\n",
       " 168: 94,\n",
       " 227: 94,\n",
       " 415: 94,\n",
       " 592: 94,\n",
       " 244: 93,\n",
       " 370: 93,\n",
       " 418: 93,\n",
       " 422: 93,\n",
       " 98: 92,\n",
       " 353: 90,\n",
       " 211: 89,\n",
       " 554: 89,\n",
       " 284: 88,\n",
       " 426: 88,\n",
       " 116: 87,\n",
       " 504: 87,\n",
       " 541: 87,\n",
       " 34: 86,\n",
       " 500: 86,\n",
       " 191: 85,\n",
       " 213: 84,\n",
       " 427: 84,\n",
       " 446: 84,\n",
       " 204: 83,\n",
       " 553: 83,\n",
       " 584: 83,\n",
       " 171: 82,\n",
       " 460: 82,\n",
       " 29: 81,\n",
       " 390: 81,\n",
       " 470: 80,\n",
       " 38: 78,\n",
       " 96: 78,\n",
       " 447: 78,\n",
       " 178: 77,\n",
       " 337: 77,\n",
       " 445: 77,\n",
       " 108: 76,\n",
       " 241: 76,\n",
       " 543: 76,\n",
       " 223: 75,\n",
       " 225: 75,\n",
       " 523: 75,\n",
       " 359: 74,\n",
       " 566: 74,\n",
       " 528: 73,\n",
       " 579: 73,\n",
       " 297: 72,\n",
       " 401: 72,\n",
       " 143: 71,\n",
       " 86: 70,\n",
       " 384: 70,\n",
       " 75: 69,\n",
       " 131: 69,\n",
       " 179: 69,\n",
       " 344: 69,\n",
       " 476: 69,\n",
       " 386: 68,\n",
       " 174: 67,\n",
       " 417: 67,\n",
       " 190: 66,\n",
       " 342: 66,\n",
       " 112: 65,\n",
       " 165: 65,\n",
       " 229: 65,\n",
       " 235: 65,\n",
       " 11: 64,\n",
       " 79: 64,\n",
       " 310: 64,\n",
       " 491: 64,\n",
       " 546: 64,\n",
       " 152: 63,\n",
       " 70: 62,\n",
       " 345: 62,\n",
       " 78: 61,\n",
       " 101: 61,\n",
       " 395: 61,\n",
       " 493: 61,\n",
       " 585: 61,\n",
       " 36: 60,\n",
       " 404: 60,\n",
       " 151: 59,\n",
       " 343: 59,\n",
       " 458: 59,\n",
       " 121: 58,\n",
       " 149: 58,\n",
       " 429: 58,\n",
       " 430: 58,\n",
       " 526: 58,\n",
       " 183: 57,\n",
       " 262: 57,\n",
       " 267: 57,\n",
       " 455: 57,\n",
       " 88: 56,\n",
       " 94: 56,\n",
       " 102: 56,\n",
       " 123: 56,\n",
       " 264: 56,\n",
       " 321: 56,\n",
       " 336: 56,\n",
       " 413: 56,\n",
       " 486: 56,\n",
       " 487: 56,\n",
       " 558: 56,\n",
       " 582: 56,\n",
       " 583: 56,\n",
       " 588: 56,\n",
       " 273: 55,\n",
       " 348: 55,\n",
       " 90: 54,\n",
       " 224: 54,\n",
       " 591: 54,\n",
       " 99: 53,\n",
       " 261: 53,\n",
       " 303: 53,\n",
       " 316: 53,\n",
       " 341: 52,\n",
       " 511: 52,\n",
       " 110: 51,\n",
       " 248: 51,\n",
       " 416: 51,\n",
       " 450: 51,\n",
       " 497: 51,\n",
       " 31: 50,\n",
       " 124: 50,\n",
       " 170: 50,\n",
       " 237: 50,\n",
       " 457: 50,\n",
       " 512: 50,\n",
       " 532: 50,\n",
       " 14: 48,\n",
       " 44: 48,\n",
       " 148: 48,\n",
       " 188: 48,\n",
       " 327: 48,\n",
       " 378: 48,\n",
       " 402: 48,\n",
       " 8: 47,\n",
       " 185: 47,\n",
       " 253: 47,\n",
       " 537: 47,\n",
       " 9: 46,\n",
       " 56: 46,\n",
       " 69: 46,\n",
       " 155: 46,\n",
       " 398: 46,\n",
       " 72: 45,\n",
       " 203: 45,\n",
       " 347: 45,\n",
       " 441: 45,\n",
       " 454: 45,\n",
       " 501: 45,\n",
       " 5: 44,\n",
       " 238: 44,\n",
       " 255: 44,\n",
       " 271: 43,\n",
       " 400: 43,\n",
       " 456: 43,\n",
       " 46: 42,\n",
       " 435: 42,\n",
       " 444: 42,\n",
       " 506: 42,\n",
       " 540: 42,\n",
       " 276: 41,\n",
       " 295: 41,\n",
       " 358: 41,\n",
       " 371: 41,\n",
       " 270: 40,\n",
       " 350: 40,\n",
       " 521: 40,\n",
       " 536: 40,\n",
       " 581: 40,\n",
       " 589: 40,\n",
       " 3: 39,\n",
       " 61: 39,\n",
       " 161: 39,\n",
       " 338: 39,\n",
       " 126: 38,\n",
       " 142: 38,\n",
       " 162: 38,\n",
       " 252: 38,\n",
       " 449: 38,\n",
       " 533: 38,\n",
       " 539: 38,\n",
       " 349: 37,\n",
       " 421: 37,\n",
       " 443: 37,\n",
       " 473: 37,\n",
       " 538: 37,\n",
       " 609: 37,\n",
       " 67: 36,\n",
       " 97: 36,\n",
       " 164: 36,\n",
       " 176: 36,\n",
       " 243: 36,\n",
       " 285: 36,\n",
       " 379: 36,\n",
       " 399: 36,\n",
       " 575: 36,\n",
       " 71: 35,\n",
       " 133: 35,\n",
       " 134: 35,\n",
       " 193: 35,\n",
       " 197: 35,\n",
       " 209: 35,\n",
       " 242: 35,\n",
       " 283: 35,\n",
       " 319: 35,\n",
       " 498: 35,\n",
       " 502: 35,\n",
       " 30: 34,\n",
       " 65: 34,\n",
       " 85: 34,\n",
       " 107: 34,\n",
       " 154: 34,\n",
       " 383: 34,\n",
       " 389: 34,\n",
       " 403: 34,\n",
       " 451: 34,\n",
       " 48: 33,\n",
       " 54: 33,\n",
       " 106: 33,\n",
       " 128: 33,\n",
       " 315: 33,\n",
       " 374: 33,\n",
       " 375: 33,\n",
       " 440: 33,\n",
       " 463: 33,\n",
       " 468: 33,\n",
       " 12: 32,\n",
       " 146: 32,\n",
       " 196: 32,\n",
       " 300: 32,\n",
       " 302: 32,\n",
       " 513: 32,\n",
       " 556: 32,\n",
       " 13: 31,\n",
       " 114: 31,\n",
       " 272: 31,\n",
       " 291: 31,\n",
       " 366: 31,\n",
       " 481: 31,\n",
       " 505: 31,\n",
       " 236: 30,\n",
       " 363: 30,\n",
       " 535: 30,\n",
       " 2: 29,\n",
       " 77: 29,\n",
       " 259: 29,\n",
       " 269: 29,\n",
       " 388: 29,\n",
       " 472: 29,\n",
       " 496: 29,\n",
       " 565: 29,\n",
       " 130: 28,\n",
       " 277: 28,\n",
       " 311: 28,\n",
       " 335: 28,\n",
       " 340: 28,\n",
       " 396: 28,\n",
       " 471: 28,\n",
       " 550: 28,\n",
       " 205: 27,\n",
       " 250: 27,\n",
       " 296: 27,\n",
       " 461: 27,\n",
       " 499: 27,\n",
       " 530: 27,\n",
       " 557: 27,\n",
       " 578: 27,\n",
       " 25: 26,\n",
       " 81: 26,\n",
       " 150: 26,\n",
       " 158: 26,\n",
       " 172: 26,\n",
       " 208: 26,\n",
       " 218: 26,\n",
       " 355: 26,\n",
       " 459: 26,\n",
       " 515: 26,\n",
       " 516: 26,\n",
       " 519: 26,\n",
       " 548: 26,\n",
       " 55: 25,\n",
       " 173: 25,\n",
       " 206: 25,\n",
       " 228: 25,\n",
       " 258: 25,\n",
       " 333: 25,\n",
       " 360: 25,\n",
       " 392: 25,\n",
       " 529: 25,\n",
       " 92: 24,\n",
       " 175: 24,\n",
       " 180: 24,\n",
       " 231: 24,\n",
       " 289: 24,\n",
       " 508: 24,\n",
       " 518: 24,\n",
       " 35: 23,\n",
       " 145: 23,\n",
       " 163: 23,\n",
       " 251: 23,\n",
       " 299: 23,\n",
       " 329: 23,\n",
       " 394: 23,\n",
       " 397: 23,\n",
       " 423: 23,\n",
       " 485: 23,\n",
       " 545: 23,\n",
       " 568: 23,\n",
       " 574: 23,\n",
       " 60: 22,\n",
       " 118: 22,\n",
       " 120: 22,\n",
       " 127: 22,\n",
       " 138: 22,\n",
       " 192: 22,\n",
       " 214: 22,\n",
       " 407: 22,\n",
       " 433: 22,\n",
       " 467: 22,\n",
       " 478: 22,\n",
       " 494: 22,\n",
       " 531: 22,\n",
       " 544: 22,\n",
       " 26: 21,\n",
       " 37: 21,\n",
       " 49: 21,\n",
       " 87: 21,\n",
       " 157: 21,\n",
       " 245: 21,\n",
       " 281: 21,\n",
       " 293: 21,\n",
       " 324: 21,\n",
       " 364: 21,\n",
       " 439: 21,\n",
       " 507: 21,\n",
       " 547: 21,\n",
       " 549: 21,\n",
       " 598: 21,\n",
       " 53: 20,\n",
       " 147: 20,\n",
       " 189: 20,\n",
       " 194: 20,\n",
       " 207: 20,\n",
       " 257: 20,\n",
       " 278: 20,\n",
       " 320: 20,\n",
       " 406: 20,\n",
       " 431: 20,\n",
       " 442: 20,\n",
       " 569: 20,\n",
       " 576: 20,\n",
       " 595: 20}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.distribution_by_number()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distribution_by_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returns the distribution of users by average or median ratings made by them.\n"
     ]
    }
   ],
   "source": [
    "print(users.distribution_by_metric.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.3 ms ± 564 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit users.distribution_by_metric('average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{53: 5.0,\n",
       " 251: 4.87,\n",
       " 515: 4.85,\n",
       " 25: 4.81,\n",
       " 30: 4.74,\n",
       " 523: 4.69,\n",
       " 348: 4.67,\n",
       " 171: 4.63,\n",
       " 452: 4.56,\n",
       " 43: 4.55,\n",
       " 122: 4.55,\n",
       " 371: 4.55,\n",
       " 441: 4.52,\n",
       " 400: 4.51,\n",
       " 52: 4.48,\n",
       " 538: 4.47,\n",
       " 168: 4.46,\n",
       " 417: 4.46,\n",
       " 543: 4.45,\n",
       " 106: 4.44,\n",
       " 319: 4.43,\n",
       " 601: 4.43,\n",
       " 413: 4.41,\n",
       " 475: 4.41,\n",
       " 188: 4.4,\n",
       " 12: 4.39,\n",
       " 276: 4.39,\n",
       " 154: 4.38,\n",
       " 533: 4.38,\n",
       " 581: 4.38,\n",
       " 1: 4.37,\n",
       " 69: 4.37,\n",
       " 586: 4.37,\n",
       " 59: 4.36,\n",
       " 128: 4.36,\n",
       " 544: 4.36,\n",
       " 253: 4.35,\n",
       " 459: 4.35,\n",
       " 553: 4.34,\n",
       " 585: 4.34,\n",
       " 519: 4.33,\n",
       " 70: 4.32,\n",
       " 336: 4.32,\n",
       " 435: 4.32,\n",
       " 300: 4.3,\n",
       " 93: 4.29,\n",
       " 532: 4.28,\n",
       " 74: 4.27,\n",
       " 49: 4.26,\n",
       " 80: 4.26,\n",
       " 224: 4.26,\n",
       " 291: 4.26,\n",
       " 164: 4.25,\n",
       " 169: 4.25,\n",
       " 246: 4.25,\n",
       " 398: 4.25,\n",
       " 162: 4.24,\n",
       " 209: 4.24,\n",
       " 362: 4.24,\n",
       " 494: 4.23,\n",
       " 250: 4.22,\n",
       " 17: 4.21,\n",
       " 337: 4.21,\n",
       " 340: 4.21,\n",
       " 573: 4.21,\n",
       " 79: 4.2,\n",
       " 227: 4.2,\n",
       " 252: 4.2,\n",
       " 258: 4.2,\n",
       " 460: 4.2,\n",
       " 595: 4.2,\n",
       " 97: 4.19,\n",
       " 364: 4.19,\n",
       " 526: 4.19,\n",
       " 119: 4.18,\n",
       " 267: 4.18,\n",
       " 505: 4.18,\n",
       " 296: 4.17,\n",
       " 72: 4.16,\n",
       " 465: 4.16,\n",
       " 491: 4.16,\n",
       " 458: 4.15,\n",
       " 29: 4.14,\n",
       " 37: 4.14,\n",
       " 243: 4.14,\n",
       " 290: 4.14,\n",
       " 547: 4.14,\n",
       " 221: 4.13,\n",
       " 568: 4.13,\n",
       " 105: 4.12,\n",
       " 389: 4.12,\n",
       " 439: 4.12,\n",
       " 443: 4.12,\n",
       " 472: 4.12,\n",
       " 511: 4.12,\n",
       " 527: 4.12,\n",
       " 572: 4.12,\n",
       " 407: 4.11,\n",
       " 421: 4.11,\n",
       " 550: 4.11,\n",
       " 584: 4.11,\n",
       " 189: 4.1,\n",
       " 201: 4.1,\n",
       " 327: 4.1,\n",
       " 548: 4.1,\n",
       " 35: 4.09,\n",
       " 178: 4.09,\n",
       " 275: 4.09,\n",
       " 408: 4.09,\n",
       " 415: 4.09,\n",
       " 562: 4.09,\n",
       " 62: 4.08,\n",
       " 186: 4.08,\n",
       " 210: 4.08,\n",
       " 556: 4.08,\n",
       " 90: 4.07,\n",
       " 166: 4.07,\n",
       " 339: 4.07,\n",
       " 95: 4.06,\n",
       " 176: 4.06,\n",
       " 343: 4.06,\n",
       " 376: 4.06,\n",
       " 410: 4.06,\n",
       " 498: 4.06,\n",
       " 537: 4.06,\n",
       " 61: 4.05,\n",
       " 192: 4.05,\n",
       " 88: 4.04,\n",
       " 123: 4.04,\n",
       " 206: 4.04,\n",
       " 48: 4.03,\n",
       " 65: 4.03,\n",
       " 239: 4.03,\n",
       " 282: 4.03,\n",
       " 582: 4.03,\n",
       " 589: 4.03,\n",
       " 66: 4.02,\n",
       " 152: 4.02,\n",
       " 326: 4.02,\n",
       " 356: 4.02,\n",
       " 486: 4.02,\n",
       " 405: 4.01,\n",
       " 495: 4.01,\n",
       " 39: 4.0,\n",
       " 46: 4.0,\n",
       " 77: 4.0,\n",
       " 273: 4.0,\n",
       " 302: 4.0,\n",
       " 378: 4.0,\n",
       " 450: 4.0,\n",
       " 540: 4.0,\n",
       " 554: 4.0,\n",
       " 569: 4.0,\n",
       " 108: 3.99,\n",
       " 124: 3.99,\n",
       " 137: 3.98,\n",
       " 241: 3.98,\n",
       " 254: 3.98,\n",
       " 429: 3.98,\n",
       " 587: 3.98,\n",
       " 597: 3.98,\n",
       " 67: 3.97,\n",
       " 236: 3.97,\n",
       " 579: 3.97,\n",
       " 204: 3.96,\n",
       " 220: 3.96,\n",
       " 285: 3.96,\n",
       " 357: 3.96,\n",
       " 397: 3.96,\n",
       " 574: 3.96,\n",
       " 578: 3.96,\n",
       " 2: 3.95,\n",
       " 87: 3.95,\n",
       " 100: 3.95,\n",
       " 256: 3.95,\n",
       " 366: 3.95,\n",
       " 92: 3.94,\n",
       " 196: 3.94,\n",
       " 399: 3.94,\n",
       " 453: 3.94,\n",
       " 86: 3.93,\n",
       " 466: 3.93,\n",
       " 558: 3.93,\n",
       " 31: 3.92,\n",
       " 129: 3.92,\n",
       " 305: 3.92,\n",
       " 594: 3.92,\n",
       " 98: 3.91,\n",
       " 103: 3.91,\n",
       " 107: 3.91,\n",
       " 190: 3.91,\n",
       " 215: 3.91,\n",
       " 240: 3.91,\n",
       " 303: 3.91,\n",
       " 375: 3.91,\n",
       " 377: 3.91,\n",
       " 58: 3.9,\n",
       " 211: 3.9,\n",
       " 280: 3.9,\n",
       " 345: 3.9,\n",
       " 412: 3.89,\n",
       " 440: 3.89,\n",
       " 513: 3.89,\n",
       " 45: 3.88,\n",
       " 96: 3.88,\n",
       " 278: 3.88,\n",
       " 355: 3.88,\n",
       " 471: 3.88,\n",
       " 488: 3.88,\n",
       " 520: 3.88,\n",
       " 99: 3.87,\n",
       " 205: 3.87,\n",
       " 304: 3.87,\n",
       " 447: 3.87,\n",
       " 485: 3.87,\n",
       " 492: 3.87,\n",
       " 125: 3.86,\n",
       " 197: 3.86,\n",
       " 261: 3.86,\n",
       " 367: 3.86,\n",
       " 445: 3.86,\n",
       " 231: 3.85,\n",
       " 402: 3.85,\n",
       " 557: 3.85,\n",
       " 203: 3.84,\n",
       " 309: 3.84,\n",
       " 390: 3.84,\n",
       " 393: 3.84,\n",
       " 409: 3.84,\n",
       " 161: 3.83,\n",
       " 172: 3.83,\n",
       " 213: 3.83,\n",
       " 499: 3.83,\n",
       " 522: 3.83,\n",
       " 118: 3.82,\n",
       " 142: 3.82,\n",
       " 183: 3.82,\n",
       " 202: 3.82,\n",
       " 420: 3.82,\n",
       " 504: 3.82,\n",
       " 200: 3.81,\n",
       " 444: 3.81,\n",
       " 456: 3.81,\n",
       " 484: 3.81,\n",
       " 598: 3.81,\n",
       " 56: 3.8,\n",
       " 193: 3.8,\n",
       " 341: 3.8,\n",
       " 419: 3.8,\n",
       " 437: 3.8,\n",
       " 534: 3.8,\n",
       " 539: 3.8,\n",
       " 33: 3.79,\n",
       " 286: 3.79,\n",
       " 383: 3.79,\n",
       " 451: 3.79,\n",
       " 463: 3.79,\n",
       " 607: 3.79,\n",
       " 11: 3.78,\n",
       " 51: 3.78,\n",
       " 179: 3.78,\n",
       " 187: 3.78,\n",
       " 352: 3.78,\n",
       " 434: 3.78,\n",
       " 512: 3.78,\n",
       " 530: 3.78,\n",
       " 40: 3.77,\n",
       " 64: 3.77,\n",
       " 115: 3.77,\n",
       " 244: 3.77,\n",
       " 344: 3.77,\n",
       " 433: 3.77,\n",
       " 454: 3.77,\n",
       " 531: 3.77,\n",
       " 260: 3.76,\n",
       " 318: 3.76,\n",
       " 403: 3.76,\n",
       " 32: 3.75,\n",
       " 247: 3.75,\n",
       " 248: 3.75,\n",
       " 464: 3.75,\n",
       " 148: 3.74,\n",
       " 191: 3.74,\n",
       " 228: 3.74,\n",
       " 229: 3.74,\n",
       " 295: 3.74,\n",
       " 430: 3.74,\n",
       " 477: 3.74,\n",
       " 18: 3.73,\n",
       " 60: 3.73,\n",
       " 110: 3.73,\n",
       " 317: 3.73,\n",
       " 349: 3.73,\n",
       " 354: 3.73,\n",
       " 16: 3.72,\n",
       " 263: 3.72,\n",
       " 284: 3.72,\n",
       " 391: 3.72,\n",
       " 423: 3.72,\n",
       " 551: 3.72,\n",
       " 73: 3.71,\n",
       " 85: 3.71,\n",
       " 184: 3.71,\n",
       " 312: 3.71,\n",
       " 249: 3.7,\n",
       " 84: 3.69,\n",
       " 156: 3.69,\n",
       " 330: 3.69,\n",
       " 493: 3.69,\n",
       " 516: 3.69,\n",
       " 610: 3.69,\n",
       " 238: 3.68,\n",
       " 335: 3.68,\n",
       " 346: 3.68,\n",
       " 426: 3.68,\n",
       " 476: 3.68,\n",
       " 351: 3.67,\n",
       " 380: 3.67,\n",
       " 424: 3.67,\n",
       " 469: 3.67,\n",
       " 549: 3.67,\n",
       " 174: 3.66,\n",
       " 216: 3.66,\n",
       " 565: 3.66,\n",
       " 606: 3.66,\n",
       " 13: 3.65,\n",
       " 23: 3.65,\n",
       " 24: 3.65,\n",
       " 113: 3.65,\n",
       " 225: 3.65,\n",
       " 235: 3.65,\n",
       " 279: 3.65,\n",
       " 299: 3.65,\n",
       " 432: 3.65,\n",
       " 5: 3.64,\n",
       " 374: 3.64,\n",
       " 418: 3.64,\n",
       " 63: 3.63,\n",
       " 135: 3.63,\n",
       " 144: 3.63,\n",
       " 272: 3.63,\n",
       " 331: 3.63,\n",
       " 269: 3.62,\n",
       " 289: 3.62,\n",
       " 388: 3.62,\n",
       " 483: 3.62,\n",
       " 155: 3.61,\n",
       " 71: 3.6,\n",
       " 242: 3.6,\n",
       " 332: 3.6,\n",
       " 521: 3.6,\n",
       " 20: 3.59,\n",
       " 112: 3.59,\n",
       " 212: 3.59,\n",
       " 592: 3.59,\n",
       " 150: 3.58,\n",
       " 564: 3.58,\n",
       " 8: 3.57,\n",
       " 42: 3.57,\n",
       " 134: 3.57,\n",
       " 277: 3.57,\n",
       " 321: 3.57,\n",
       " 497: 3.57,\n",
       " 560: 3.57,\n",
       " 577: 3.57,\n",
       " 4: 3.56,\n",
       " 101: 3.56,\n",
       " 180: 3.56,\n",
       " 264: 3.56,\n",
       " 347: 3.56,\n",
       " 27: 3.55,\n",
       " 370: 3.55,\n",
       " 130: 3.54,\n",
       " 141: 3.54,\n",
       " 151: 3.54,\n",
       " 165: 3.54,\n",
       " 175: 3.54,\n",
       " 325: 3.54,\n",
       " 381: 3.54,\n",
       " 518: 3.54,\n",
       " 525: 3.54,\n",
       " 566: 3.54,\n",
       " 185: 3.53,\n",
       " 195: 3.53,\n",
       " 310: 3.53,\n",
       " 401: 3.53,\n",
       " 425: 3.53,\n",
       " 580: 3.53,\n",
       " 138: 3.52,\n",
       " 320: 3.52,\n",
       " 104: 3.51,\n",
       " 182: 3.51,\n",
       " 382: 3.51,\n",
       " 470: 3.51,\n",
       " 542: 3.51,\n",
       " 603: 3.51,\n",
       " 140: 3.5,\n",
       " 234: 3.5,\n",
       " 266: 3.5,\n",
       " 596: 3.5,\n",
       " 6: 3.49,\n",
       " 198: 3.49,\n",
       " 353: 3.49,\n",
       " 157: 3.48,\n",
       " 173: 3.48,\n",
       " 194: 3.48,\n",
       " 226: 3.48,\n",
       " 604: 3.48,\n",
       " 89: 3.47,\n",
       " 528: 3.47,\n",
       " 455: 3.46,\n",
       " 457: 3.46,\n",
       " 524: 3.46,\n",
       " 555: 3.46,\n",
       " 15: 3.45,\n",
       " 114: 3.44,\n",
       " 116: 3.44,\n",
       " 131: 3.44,\n",
       " 167: 3.44,\n",
       " 546: 3.44,\n",
       " 313: 3.43,\n",
       " 502: 3.43,\n",
       " 34: 3.42,\n",
       " 158: 3.42,\n",
       " 334: 3.42,\n",
       " 359: 3.42,\n",
       " 473: 3.42,\n",
       " 570: 3.42,\n",
       " 120: 3.41,\n",
       " 322: 3.41,\n",
       " 462: 3.41,\n",
       " 467: 3.41,\n",
       " 482: 3.41,\n",
       " 496: 3.41,\n",
       " 14: 3.4,\n",
       " 91: 3.4,\n",
       " 199: 3.4,\n",
       " 385: 3.4,\n",
       " 404: 3.4,\n",
       " 474: 3.4,\n",
       " 536: 3.4,\n",
       " 57: 3.39,\n",
       " 369: 3.39,\n",
       " 379: 3.39,\n",
       " 414: 3.39,\n",
       " 468: 3.39,\n",
       " 541: 3.39,\n",
       " 602: 3.39,\n",
       " 82: 3.38,\n",
       " 147: 3.38,\n",
       " 177: 3.38,\n",
       " 507: 3.38,\n",
       " 218: 3.37,\n",
       " 545: 3.37,\n",
       " 561: 3.37,\n",
       " 102: 3.36,\n",
       " 237: 3.36,\n",
       " 315: 3.36,\n",
       " 360: 3.36,\n",
       " 372: 3.36,\n",
       " 438: 3.36,\n",
       " 590: 3.36,\n",
       " 44: 3.35,\n",
       " 145: 3.35,\n",
       " 265: 3.35,\n",
       " 111: 3.34,\n",
       " 117: 3.34,\n",
       " 170: 3.34,\n",
       " 503: 3.34,\n",
       " 136: 3.32,\n",
       " 143: 3.32,\n",
       " 301: 3.32,\n",
       " 306: 3.32,\n",
       " 422: 3.32,\n",
       " 479: 3.32,\n",
       " 83: 3.31,\n",
       " 208: 3.31,\n",
       " 283: 3.31,\n",
       " 514: 3.31,\n",
       " 233: 3.3,\n",
       " 292: 3.3,\n",
       " 363: 3.3,\n",
       " 563: 3.3,\n",
       " 121: 3.29,\n",
       " 126: 3.29,\n",
       " 449: 3.29,\n",
       " 559: 3.29,\n",
       " 583: 3.29,\n",
       " 10: 3.28,\n",
       " 480: 3.28,\n",
       " 591: 3.28,\n",
       " 159: 3.27,\n",
       " 223: 3.27,\n",
       " 268: 3.27,\n",
       " 593: 3.27,\n",
       " 609: 3.27,\n",
       " 9: 3.26,\n",
       " 21: 3.26,\n",
       " 358: 3.26,\n",
       " 387: 3.26,\n",
       " 411: 3.26,\n",
       " 506: 3.26,\n",
       " 41: 3.25,\n",
       " 232: 3.25,\n",
       " 350: 3.25,\n",
       " 406: 3.25,\n",
       " 588: 3.25,\n",
       " 26: 3.24,\n",
       " 274: 3.24,\n",
       " 500: 3.24,\n",
       " 7: 3.23,\n",
       " 68: 3.23,\n",
       " 75: 3.23,\n",
       " 328: 3.23,\n",
       " 38: 3.22,\n",
       " 109: 3.22,\n",
       " 509: 3.22,\n",
       " 281: 3.21,\n",
       " 446: 3.21,\n",
       " 605: 3.21,\n",
       " 257: 3.2,\n",
       " 270: 3.2,\n",
       " 392: 3.2,\n",
       " 501: 3.2,\n",
       " 529: 3.2,\n",
       " 271: 3.19,\n",
       " 373: 3.19,\n",
       " 361: 3.18,\n",
       " 436: 3.18,\n",
       " 219: 3.17,\n",
       " 222: 3.17,\n",
       " 323: 3.17,\n",
       " 575: 3.17,\n",
       " 78: 3.16,\n",
       " 490: 3.16,\n",
       " 288: 3.15,\n",
       " 146: 3.14,\n",
       " 324: 3.14,\n",
       " 396: 3.14,\n",
       " 487: 3.14,\n",
       " 608: 3.13,\n",
       " 259: 3.12,\n",
       " 552: 3.12,\n",
       " 127: 3.11,\n",
       " 262: 3.11,\n",
       " 427: 3.1,\n",
       " 576: 3.1,\n",
       " 384: 3.09,\n",
       " 76: 3.08,\n",
       " 416: 3.07,\n",
       " 47: 3.05,\n",
       " 314: 3.05,\n",
       " 395: 3.05,\n",
       " 94: 3.04,\n",
       " 132: 3.04,\n",
       " 54: 3.03,\n",
       " 28: 3.02,\n",
       " 489: 3.02,\n",
       " 133: 3.0,\n",
       " 163: 3.0,\n",
       " 316: 3.0,\n",
       " 600: 2.99,\n",
       " 394: 2.96,\n",
       " 181: 2.94,\n",
       " 338: 2.94,\n",
       " 342: 2.94,\n",
       " 461: 2.94,\n",
       " 510: 2.9,\n",
       " 207: 2.88,\n",
       " 329: 2.87,\n",
       " 214: 2.86,\n",
       " 230: 2.86,\n",
       " 448: 2.85,\n",
       " 55: 2.84,\n",
       " 368: 2.84,\n",
       " 478: 2.82,\n",
       " 481: 2.81,\n",
       " 50: 2.78,\n",
       " 81: 2.77,\n",
       " 217: 2.76,\n",
       " 365: 2.75,\n",
       " 386: 2.75,\n",
       " 431: 2.73,\n",
       " 149: 2.72,\n",
       " 160: 2.71,\n",
       " 245: 2.71,\n",
       " 307: 2.67,\n",
       " 535: 2.67,\n",
       " 333: 2.64,\n",
       " 428: 2.64,\n",
       " 599: 2.64,\n",
       " 36: 2.63,\n",
       " 287: 2.62,\n",
       " 293: 2.62,\n",
       " 19: 2.61,\n",
       " 294: 2.61,\n",
       " 297: 2.6,\n",
       " 22: 2.57,\n",
       " 255: 2.57,\n",
       " 571: 2.57,\n",
       " 3: 2.44,\n",
       " 308: 2.43,\n",
       " 517: 2.39,\n",
       " 298: 2.36,\n",
       " 311: 2.34,\n",
       " 567: 2.25,\n",
       " 153: 2.22,\n",
       " 508: 2.15,\n",
       " 139: 2.14,\n",
       " 442: 1.27}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.distribution_by_metric('average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.4 ms ± 415 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit users.distribution_by_metric('median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 5.0,\n",
       " 25: 5.0,\n",
       " 30: 5.0,\n",
       " 43: 5.0,\n",
       " 52: 5.0,\n",
       " 53: 5.0,\n",
       " 59: 5.0,\n",
       " 69: 5.0,\n",
       " 77: 5.0,\n",
       " 106: 5.0,\n",
       " 154: 5.0,\n",
       " 164: 5.0,\n",
       " 171: 5.0,\n",
       " 188: 5.0,\n",
       " 224: 5.0,\n",
       " 236: 5.0,\n",
       " 251: 5.0,\n",
       " 258: 5.0,\n",
       " 267: 5.0,\n",
       " 276: 5.0,\n",
       " 348: 5.0,\n",
       " 393: 5.0,\n",
       " 413: 5.0,\n",
       " 417: 5.0,\n",
       " 441: 5.0,\n",
       " 452: 5.0,\n",
       " 494: 5.0,\n",
       " 515: 5.0,\n",
       " 523: 5.0,\n",
       " 533: 5.0,\n",
       " 543: 5.0,\n",
       " 544: 5.0,\n",
       " 598: 5.0,\n",
       " 12: 4.75,\n",
       " 49: 4.5,\n",
       " 70: 4.5,\n",
       " 72: 4.5,\n",
       " 88: 4.5,\n",
       " 122: 4.5,\n",
       " 168: 4.5,\n",
       " 169: 4.5,\n",
       " 178: 4.5,\n",
       " 209: 4.5,\n",
       " 210: 4.5,\n",
       " 221: 4.5,\n",
       " 246: 4.5,\n",
       " 250: 4.5,\n",
       " 253: 4.5,\n",
       " 295: 4.5,\n",
       " 296: 4.5,\n",
       " 319: 4.5,\n",
       " 336: 4.5,\n",
       " 371: 4.5,\n",
       " 398: 4.5,\n",
       " 399: 4.5,\n",
       " 400: 4.5,\n",
       " 421: 4.5,\n",
       " 435: 4.5,\n",
       " 459: 4.5,\n",
       " 460: 4.5,\n",
       " 475: 4.5,\n",
       " 495: 4.5,\n",
       " 505: 4.5,\n",
       " 537: 4.5,\n",
       " 538: 4.5,\n",
       " 548: 4.5,\n",
       " 553: 4.5,\n",
       " 573: 4.5,\n",
       " 578: 4.5,\n",
       " 581: 4.5,\n",
       " 585: 4.5,\n",
       " 586: 4.5,\n",
       " 594: 4.5,\n",
       " 601: 4.5,\n",
       " 138: 4.25,\n",
       " 327: 4.25,\n",
       " 2: 4.0,\n",
       " 4: 4.0,\n",
       " 5: 4.0,\n",
       " 11: 4.0,\n",
       " 13: 4.0,\n",
       " 16: 4.0,\n",
       " 17: 4.0,\n",
       " 18: 4.0,\n",
       " 27: 4.0,\n",
       " 29: 4.0,\n",
       " 31: 4.0,\n",
       " 32: 4.0,\n",
       " 33: 4.0,\n",
       " 34: 4.0,\n",
       " 35: 4.0,\n",
       " 37: 4.0,\n",
       " 39: 4.0,\n",
       " 40: 4.0,\n",
       " 42: 4.0,\n",
       " 45: 4.0,\n",
       " 46: 4.0,\n",
       " 48: 4.0,\n",
       " 51: 4.0,\n",
       " 56: 4.0,\n",
       " 57: 4.0,\n",
       " 58: 4.0,\n",
       " 60: 4.0,\n",
       " 61: 4.0,\n",
       " 62: 4.0,\n",
       " 63: 4.0,\n",
       " 64: 4.0,\n",
       " 65: 4.0,\n",
       " 66: 4.0,\n",
       " 67: 4.0,\n",
       " 71: 4.0,\n",
       " 73: 4.0,\n",
       " 74: 4.0,\n",
       " 75: 4.0,\n",
       " 79: 4.0,\n",
       " 80: 4.0,\n",
       " 84: 4.0,\n",
       " 85: 4.0,\n",
       " 86: 4.0,\n",
       " 87: 4.0,\n",
       " 90: 4.0,\n",
       " 92: 4.0,\n",
       " 93: 4.0,\n",
       " 95: 4.0,\n",
       " 96: 4.0,\n",
       " 97: 4.0,\n",
       " 98: 4.0,\n",
       " 99: 4.0,\n",
       " 100: 4.0,\n",
       " 101: 4.0,\n",
       " 103: 4.0,\n",
       " 105: 4.0,\n",
       " 107: 4.0,\n",
       " 108: 4.0,\n",
       " 110: 4.0,\n",
       " 112: 4.0,\n",
       " 113: 4.0,\n",
       " 115: 4.0,\n",
       " 118: 4.0,\n",
       " 119: 4.0,\n",
       " 123: 4.0,\n",
       " 124: 4.0,\n",
       " 125: 4.0,\n",
       " 128: 4.0,\n",
       " 129: 4.0,\n",
       " 135: 4.0,\n",
       " 137: 4.0,\n",
       " 142: 4.0,\n",
       " 147: 4.0,\n",
       " 148: 4.0,\n",
       " 151: 4.0,\n",
       " 152: 4.0,\n",
       " 155: 4.0,\n",
       " 156: 4.0,\n",
       " 161: 4.0,\n",
       " 162: 4.0,\n",
       " 166: 4.0,\n",
       " 172: 4.0,\n",
       " 175: 4.0,\n",
       " 176: 4.0,\n",
       " 179: 4.0,\n",
       " 183: 4.0,\n",
       " 184: 4.0,\n",
       " 185: 4.0,\n",
       " 186: 4.0,\n",
       " 187: 4.0,\n",
       " 189: 4.0,\n",
       " 190: 4.0,\n",
       " 191: 4.0,\n",
       " 192: 4.0,\n",
       " 193: 4.0,\n",
       " 195: 4.0,\n",
       " 196: 4.0,\n",
       " 197: 4.0,\n",
       " 198: 4.0,\n",
       " 200: 4.0,\n",
       " 201: 4.0,\n",
       " 202: 4.0,\n",
       " 203: 4.0,\n",
       " 204: 4.0,\n",
       " 205: 4.0,\n",
       " 206: 4.0,\n",
       " 211: 4.0,\n",
       " 213: 4.0,\n",
       " 215: 4.0,\n",
       " 216: 4.0,\n",
       " 218: 4.0,\n",
       " 220: 4.0,\n",
       " 225: 4.0,\n",
       " 227: 4.0,\n",
       " 228: 4.0,\n",
       " 229: 4.0,\n",
       " 231: 4.0,\n",
       " 234: 4.0,\n",
       " 235: 4.0,\n",
       " 238: 4.0,\n",
       " 239: 4.0,\n",
       " 240: 4.0,\n",
       " 241: 4.0,\n",
       " 243: 4.0,\n",
       " 244: 4.0,\n",
       " 247: 4.0,\n",
       " 252: 4.0,\n",
       " 254: 4.0,\n",
       " 256: 4.0,\n",
       " 259: 4.0,\n",
       " 260: 4.0,\n",
       " 261: 4.0,\n",
       " 263: 4.0,\n",
       " 266: 4.0,\n",
       " 269: 4.0,\n",
       " 272: 4.0,\n",
       " 273: 4.0,\n",
       " 275: 4.0,\n",
       " 278: 4.0,\n",
       " 280: 4.0,\n",
       " 282: 4.0,\n",
       " 284: 4.0,\n",
       " 285: 4.0,\n",
       " 286: 4.0,\n",
       " 290: 4.0,\n",
       " 291: 4.0,\n",
       " 299: 4.0,\n",
       " 300: 4.0,\n",
       " 301: 4.0,\n",
       " 302: 4.0,\n",
       " 304: 4.0,\n",
       " 305: 4.0,\n",
       " 309: 4.0,\n",
       " 310: 4.0,\n",
       " 312: 4.0,\n",
       " 313: 4.0,\n",
       " 317: 4.0,\n",
       " 318: 4.0,\n",
       " 325: 4.0,\n",
       " 326: 4.0,\n",
       " 330: 4.0,\n",
       " 331: 4.0,\n",
       " 335: 4.0,\n",
       " 337: 4.0,\n",
       " 339: 4.0,\n",
       " 340: 4.0,\n",
       " 341: 4.0,\n",
       " 343: 4.0,\n",
       " 344: 4.0,\n",
       " 345: 4.0,\n",
       " 346: 4.0,\n",
       " 347: 4.0,\n",
       " 349: 4.0,\n",
       " 352: 4.0,\n",
       " 354: 4.0,\n",
       " 355: 4.0,\n",
       " 356: 4.0,\n",
       " 357: 4.0,\n",
       " 358: 4.0,\n",
       " 360: 4.0,\n",
       " 362: 4.0,\n",
       " 364: 4.0,\n",
       " 366: 4.0,\n",
       " 367: 4.0,\n",
       " 374: 4.0,\n",
       " 375: 4.0,\n",
       " 376: 4.0,\n",
       " 377: 4.0,\n",
       " 378: 4.0,\n",
       " 380: 4.0,\n",
       " 383: 4.0,\n",
       " 388: 4.0,\n",
       " 389: 4.0,\n",
       " 390: 4.0,\n",
       " 391: 4.0,\n",
       " 397: 4.0,\n",
       " 402: 4.0,\n",
       " 405: 4.0,\n",
       " 407: 4.0,\n",
       " 408: 4.0,\n",
       " 409: 4.0,\n",
       " 410: 4.0,\n",
       " 412: 4.0,\n",
       " 415: 4.0,\n",
       " 418: 4.0,\n",
       " 419: 4.0,\n",
       " 420: 4.0,\n",
       " 422: 4.0,\n",
       " 423: 4.0,\n",
       " 426: 4.0,\n",
       " 429: 4.0,\n",
       " 430: 4.0,\n",
       " 432: 4.0,\n",
       " 433: 4.0,\n",
       " 434: 4.0,\n",
       " 437: 4.0,\n",
       " 439: 4.0,\n",
       " 440: 4.0,\n",
       " 443: 4.0,\n",
       " 444: 4.0,\n",
       " 445: 4.0,\n",
       " 447: 4.0,\n",
       " 450: 4.0,\n",
       " 451: 4.0,\n",
       " 453: 4.0,\n",
       " 456: 4.0,\n",
       " 458: 4.0,\n",
       " 461: 4.0,\n",
       " 463: 4.0,\n",
       " 464: 4.0,\n",
       " 465: 4.0,\n",
       " 466: 4.0,\n",
       " 467: 4.0,\n",
       " 469: 4.0,\n",
       " 471: 4.0,\n",
       " 472: 4.0,\n",
       " 476: 4.0,\n",
       " 477: 4.0,\n",
       " 482: 4.0,\n",
       " 483: 4.0,\n",
       " 484: 4.0,\n",
       " 485: 4.0,\n",
       " 486: 4.0,\n",
       " 488: 4.0,\n",
       " 491: 4.0,\n",
       " 492: 4.0,\n",
       " 493: 4.0,\n",
       " 497: 4.0,\n",
       " 498: 4.0,\n",
       " 499: 4.0,\n",
       " 500: 4.0,\n",
       " 502: 4.0,\n",
       " 504: 4.0,\n",
       " 511: 4.0,\n",
       " 512: 4.0,\n",
       " 513: 4.0,\n",
       " 516: 4.0,\n",
       " 518: 4.0,\n",
       " 519: 4.0,\n",
       " 520: 4.0,\n",
       " 521: 4.0,\n",
       " 522: 4.0,\n",
       " 526: 4.0,\n",
       " 527: 4.0,\n",
       " 530: 4.0,\n",
       " 531: 4.0,\n",
       " 532: 4.0,\n",
       " 534: 4.0,\n",
       " 540: 4.0,\n",
       " 542: 4.0,\n",
       " 546: 4.0,\n",
       " 547: 4.0,\n",
       " 549: 4.0,\n",
       " 550: 4.0,\n",
       " 551: 4.0,\n",
       " 554: 4.0,\n",
       " 556: 4.0,\n",
       " 557: 4.0,\n",
       " 558: 4.0,\n",
       " 562: 4.0,\n",
       " 565: 4.0,\n",
       " 566: 4.0,\n",
       " 568: 4.0,\n",
       " 569: 4.0,\n",
       " 572: 4.0,\n",
       " 574: 4.0,\n",
       " 577: 4.0,\n",
       " 579: 4.0,\n",
       " 580: 4.0,\n",
       " 582: 4.0,\n",
       " 584: 4.0,\n",
       " 587: 4.0,\n",
       " 589: 4.0,\n",
       " 595: 4.0,\n",
       " 597: 4.0,\n",
       " 603: 4.0,\n",
       " 606: 4.0,\n",
       " 607: 4.0,\n",
       " 20: 3.75,\n",
       " 180: 3.75,\n",
       " 264: 3.75,\n",
       " 403: 3.75,\n",
       " 539: 3.75,\n",
       " 7: 3.5,\n",
       " 10: 3.5,\n",
       " 15: 3.5,\n",
       " 21: 3.5,\n",
       " 23: 3.5,\n",
       " 24: 3.5,\n",
       " 41: 3.5,\n",
       " 76: 3.5,\n",
       " 82: 3.5,\n",
       " 83: 3.5,\n",
       " 89: 3.5,\n",
       " 91: 3.5,\n",
       " 104: 3.5,\n",
       " 111: 3.5,\n",
       " 114: 3.5,\n",
       " 116: 3.5,\n",
       " 127: 3.5,\n",
       " 130: 3.5,\n",
       " 131: 3.5,\n",
       " 140: 3.5,\n",
       " 141: 3.5,\n",
       " 143: 3.5,\n",
       " 144: 3.5,\n",
       " 158: 3.5,\n",
       " 159: 3.5,\n",
       " 167: 3.5,\n",
       " 177: 3.5,\n",
       " 182: 3.5,\n",
       " 194: 3.5,\n",
       " 199: 3.5,\n",
       " 207: 3.5,\n",
       " 208: 3.5,\n",
       " 212: 3.5,\n",
       " 219: 3.5,\n",
       " 223: 3.5,\n",
       " 226: 3.5,\n",
       " 233: 3.5,\n",
       " 237: 3.5,\n",
       " 248: 3.5,\n",
       " 249: 3.5,\n",
       " 257: 3.5,\n",
       " 274: 3.5,\n",
       " 277: 3.5,\n",
       " 279: 3.5,\n",
       " 281: 3.5,\n",
       " 289: 3.5,\n",
       " 292: 3.5,\n",
       " 303: 3.5,\n",
       " 320: 3.5,\n",
       " 322: 3.5,\n",
       " 332: 3.5,\n",
       " 334: 3.5,\n",
       " 351: 3.5,\n",
       " 359: 3.5,\n",
       " 361: 3.5,\n",
       " 369: 3.5,\n",
       " 370: 3.5,\n",
       " 381: 3.5,\n",
       " 382: 3.5,\n",
       " 387: 3.5,\n",
       " 396: 3.5,\n",
       " 401: 3.5,\n",
       " 406: 3.5,\n",
       " 414: 3.5,\n",
       " 416: 3.5,\n",
       " 424: 3.5,\n",
       " 425: 3.5,\n",
       " 438: 3.5,\n",
       " 449: 3.5,\n",
       " 454: 3.5,\n",
       " 457: 3.5,\n",
       " 462: 3.5,\n",
       " 473: 3.5,\n",
       " 474: 3.5,\n",
       " 480: 3.5,\n",
       " 489: 3.5,\n",
       " 490: 3.5,\n",
       " 496: 3.5,\n",
       " 503: 3.5,\n",
       " 509: 3.5,\n",
       " 514: 3.5,\n",
       " 525: 3.5,\n",
       " 528: 3.5,\n",
       " 545: 3.5,\n",
       " 552: 3.5,\n",
       " 560: 3.5,\n",
       " 561: 3.5,\n",
       " 563: 3.5,\n",
       " 564: 3.5,\n",
       " 570: 3.5,\n",
       " 590: 3.5,\n",
       " 593: 3.5,\n",
       " 596: 3.5,\n",
       " 610: 3.5,\n",
       " 68: 3.25,\n",
       " 306: 3.25,\n",
       " 363: 3.25,\n",
       " 487: 3.25,\n",
       " 576: 3.25,\n",
       " 583: 3.25,\n",
       " 6: 3.0,\n",
       " 8: 3.0,\n",
       " 9: 3.0,\n",
       " 14: 3.0,\n",
       " 19: 3.0,\n",
       " 22: 3.0,\n",
       " 26: 3.0,\n",
       " 28: 3.0,\n",
       " 38: 3.0,\n",
       " 44: 3.0,\n",
       " 47: 3.0,\n",
       " 50: 3.0,\n",
       " 54: 3.0,\n",
       " 55: 3.0,\n",
       " 78: 3.0,\n",
       " 81: 3.0,\n",
       " 94: 3.0,\n",
       " 102: 3.0,\n",
       " 109: 3.0,\n",
       " 117: 3.0,\n",
       " 120: 3.0,\n",
       " 121: 3.0,\n",
       " 126: 3.0,\n",
       " 132: 3.0,\n",
       " 133: 3.0,\n",
       " 134: 3.0,\n",
       " 136: 3.0,\n",
       " 145: 3.0,\n",
       " 146: 3.0,\n",
       " 149: 3.0,\n",
       " 150: 3.0,\n",
       " 157: 3.0,\n",
       " 160: 3.0,\n",
       " 163: 3.0,\n",
       " 165: 3.0,\n",
       " 170: 3.0,\n",
       " 173: 3.0,\n",
       " 174: 3.0,\n",
       " 181: 3.0,\n",
       " 214: 3.0,\n",
       " 217: 3.0,\n",
       " 222: 3.0,\n",
       " 230: 3.0,\n",
       " 232: 3.0,\n",
       " 242: 3.0,\n",
       " 245: 3.0,\n",
       " 262: 3.0,\n",
       " 265: 3.0,\n",
       " 268: 3.0,\n",
       " 270: 3.0,\n",
       " 271: 3.0,\n",
       " 283: 3.0,\n",
       " 288: 3.0,\n",
       " 294: 3.0,\n",
       " 297: 3.0,\n",
       " 314: 3.0,\n",
       " 315: 3.0,\n",
       " 316: 3.0,\n",
       " 321: 3.0,\n",
       " 323: 3.0,\n",
       " 324: 3.0,\n",
       " 328: 3.0,\n",
       " 333: 3.0,\n",
       " 338: 3.0,\n",
       " 342: 3.0,\n",
       " 350: 3.0,\n",
       " 353: 3.0,\n",
       " 365: 3.0,\n",
       " 368: 3.0,\n",
       " 372: 3.0,\n",
       " 373: 3.0,\n",
       " 379: 3.0,\n",
       " 384: 3.0,\n",
       " 385: 3.0,\n",
       " 386: 3.0,\n",
       " 392: 3.0,\n",
       " 394: 3.0,\n",
       " 395: 3.0,\n",
       " 404: 3.0,\n",
       " 411: 3.0,\n",
       " 427: 3.0,\n",
       " 428: 3.0,\n",
       " 436: 3.0,\n",
       " 446: 3.0,\n",
       " 448: 3.0,\n",
       " 455: 3.0,\n",
       " 468: 3.0,\n",
       " 470: 3.0,\n",
       " 479: 3.0,\n",
       " 481: 3.0,\n",
       " 501: 3.0,\n",
       " 506: 3.0,\n",
       " 507: 3.0,\n",
       " 510: 3.0,\n",
       " 524: 3.0,\n",
       " 529: 3.0,\n",
       " 535: 3.0,\n",
       " 536: 3.0,\n",
       " 541: 3.0,\n",
       " 555: 3.0,\n",
       " 559: 3.0,\n",
       " 575: 3.0,\n",
       " 588: 3.0,\n",
       " 591: 3.0,\n",
       " 592: 3.0,\n",
       " 600: 3.0,\n",
       " 602: 3.0,\n",
       " 604: 3.0,\n",
       " 605: 3.0,\n",
       " 608: 3.0,\n",
       " 609: 3.0,\n",
       " 311: 2.75,\n",
       " 431: 2.75,\n",
       " 478: 2.75,\n",
       " 36: 2.5,\n",
       " 287: 2.5,\n",
       " 298: 2.5,\n",
       " 307: 2.5,\n",
       " 308: 2.5,\n",
       " 517: 2.5,\n",
       " 599: 2.5,\n",
       " 139: 2.0,\n",
       " 153: 2.0,\n",
       " 255: 2.0,\n",
       " 293: 2.0,\n",
       " 329: 2.0,\n",
       " 508: 2.0,\n",
       " 567: 2.0,\n",
       " 571: 2.0,\n",
       " 442: 1.0,\n",
       " 3: 0.5}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.distribution_by_metric('median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top_by_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returns top-n users with the biggest variance of their ratings.\n"
     ]
    }
   ],
   "source": [
    "print(users.top_by_variance.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.6 ms ± 2.17 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit users.top_by_variance(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 4.26,\n",
       " 461: 3.1,\n",
       " 55: 3.09,\n",
       " 259: 2.94,\n",
       " 329: 2.92,\n",
       " 502: 2.76,\n",
       " 175: 2.75,\n",
       " 598: 2.7,\n",
       " 393: 2.61,\n",
       " 138: 2.44}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.top_by_variance(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## класс Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Класс Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала спарсим данные с сайтов https://movielens.org/movies/, http://www.imdb.com/title/tt0114709/, https://www.themoviedb.org/movie/862"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В процессе парсинга были выявлены особенности в данных:\n",
    "- деректоров фильма может быть один, а может быть много\n",
    "- поля Budget и Cumulative Worldwide Gross есть не во всех фильмах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# links = Links(\"data/links\")\n",
    "# links.parse(\"data/links_parsed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.8 ms ± 1.38 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit Links(\"data/links_parsed.csv\", parsed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'movieId': '193565',\n",
       "  'imdbId': '1636780',\n",
       "  'tmdbId': '71172',\n",
       "  'title': 'Gintama: The Movie',\n",
       "  'runtime': '1h 36m',\n",
       "  'director': 'Shinji Takamatsu',\n",
       "  'gross_worldwide': 10453259,\n",
       "  'budget': None},\n",
       " {'movieId': '193567',\n",
       "  'imdbId': '2323836',\n",
       "  'tmdbId': '255413',\n",
       "  'title': 'Anohana the Movie: The Flower We Saw That Day (Ano hi mita hana no namae wo bokutachi wa mada shiran',\n",
       "  'runtime': '1h 39m',\n",
       "  'director': 'Tatsuyuki Nagai',\n",
       "  'gross_worldwide': 109630,\n",
       "  'budget': None},\n",
       " {'movieId': '193571',\n",
       "  'imdbId': '3110014',\n",
       "  'tmdbId': '297825',\n",
       "  'title': 'Silver Spoon',\n",
       "  'runtime': '1h 51m',\n",
       "  'director': 'Keisuke Yoshida',\n",
       "  'gross_worldwide': 6803548,\n",
       "  'budget': None},\n",
       " {'movieId': '193573',\n",
       "  'imdbId': '3837248',\n",
       "  'tmdbId': '333623',\n",
       "  'title': 'Love Live! The School Idol Movie',\n",
       "  'runtime': '1h 39m',\n",
       "  'director': 'Takahiko Kyôgoku',\n",
       "  'gross_worldwide': 22069046,\n",
       "  'budget': None},\n",
       " {'movieId': '193579',\n",
       "  'imdbId': '5342766',\n",
       "  'tmdbId': '360617',\n",
       "  'title': 'Jon Stewart Has Left the Building',\n",
       "  'runtime': '1h',\n",
       "  'director': None,\n",
       "  'gross_worldwide': None,\n",
       "  'budget': None},\n",
       " {'movieId': '193581',\n",
       "  'imdbId': '5476944',\n",
       "  'tmdbId': '432131',\n",
       "  'title': 'Black Butler: Book of the Atlantic',\n",
       "  'runtime': '1h 41m',\n",
       "  'director': 'Noriyuki Abe|Stephen Hoff',\n",
       "  'gross_worldwide': 511132,\n",
       "  'budget': None},\n",
       " {'movieId': '193583',\n",
       "  'imdbId': '5914996',\n",
       "  'tmdbId': '445030',\n",
       "  'title': 'No Game No Life: Zero',\n",
       "  'runtime': '1h 50m',\n",
       "  'director': 'Atsuko Ishizuka',\n",
       "  'gross_worldwide': 6356284,\n",
       "  'budget': None},\n",
       " {'movieId': '193585',\n",
       "  'imdbId': '6397426',\n",
       "  'tmdbId': '479308',\n",
       "  'title': 'Flint',\n",
       "  'runtime': '1h 26m',\n",
       "  'director': 'Bruce Beresford',\n",
       "  'gross_worldwide': None,\n",
       "  'budget': None},\n",
       " {'movieId': '193587',\n",
       "  'imdbId': '8391976',\n",
       "  'tmdbId': '483455',\n",
       "  'title': 'Bungo Stray Dogs: Dead Apple',\n",
       "  'runtime': '1h 32m',\n",
       "  'director': 'Takuya Igarashi',\n",
       "  'gross_worldwide': 2373203,\n",
       "  'budget': None},\n",
       " {'movieId': '193609',\n",
       "  'imdbId': '0101726',\n",
       "  'tmdbId': '37891',\n",
       "  'title': 'Dice Rules',\n",
       "  'runtime': '1h 28m',\n",
       "  'director': 'Jay Dubin',\n",
       "  'gross_worldwide': 637327,\n",
       "  'budget': None}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = Links(\"data/links_parsed.csv\", parsed=True)\n",
    "links.data[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The method returns a list of lists [movieId, field1, field2, field3, ...] for the list of movies given as the argument (movieId).\n",
      "        For example, [movieId, Director, Budget, Cumulative Worldwide Gross, Runtime].\n",
      "        The values should be parsed from the IMDB webpages of the movies.\n",
      "     Sort it by movieId descendingly.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(links.get_imdb.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.3 μs ± 185 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit links.get_imdb([1, 2, 3, 106], ['movieId', 'Director', 'Budget', 'Cumulative Worldwide Gross', 'Runtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'John Lasseter', 30000000, 394436586, '1h 21m'],\n",
       " ['2', 'Joe Johnston', 65000000, 262821940, '1h 44m'],\n",
       " ['3', 'Howard Deutch', 25000000, 71518503, '1h 41m'],\n",
       " ['106', 'Doris Dörrie', None, None, '1h 44m']]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links.get_imdb([1, 2, 3, 106], ['movieId', 'Director', 'Budget', 'Cumulative Worldwide Gross', 'Runtime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top_directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        The method returns a dict with top-n directors where the keys are directors and \n",
      "        the values are numbers of movies created by them. Sort it by numbers descendingly.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(links.top_directors.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.73 ms ± 207 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit links.top_directors(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Woody Allen': 48,\n",
       " 'Alfred Hitchcock': 37,\n",
       " 'Clint Eastwood': 32,\n",
       " 'Steven Spielberg': 32}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links.top_directors(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### most_expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        The method returns a dict with top-n movies where the keys are movie titles and\n",
      "        the values are their budgets. Sort it by budgets descendingly.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(links.most_expensive.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.67 ms ± 159 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit links.most_expensive(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The Name of the Rose': 30000000000,\n",
       " 'Life Is Beautiful': 15000000000,\n",
       " 'The Handmaiden': 10000000000,\n",
       " 'Train to Busan': 10000000000,\n",
       " 'Lupin III: The Castle of Cagliostro': 5000000000,\n",
       " 'The Tale of The Princess Kaguya': 5000000000,\n",
       " 'Lady Vengeance': 4200000000,\n",
       " 'The Leopard': 2900000000,\n",
       " 'Princess Mononoke': 2400000000,\n",
       " 'Ghost in the Shell 2: Innocence': 2000000000,\n",
       " 'The Great Yokai War': 1300000000,\n",
       " 'Akira': 1100000000,\n",
       " 'Wings of Honneamise': 800000000,\n",
       " \"Kiki's Delivery Service\": 800000000,\n",
       " 'Tango': 700000000,\n",
       " 'Lola Montès': 650000000,\n",
       " 'Red Cliff': 553632000,\n",
       " '3 Idiots': 550000000,\n",
       " 'Zombie': 410000000,\n",
       " 'The Legend of Suriyothai': 400000000}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links.most_expensive(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### most_profitable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        The method returns a dict with top-n movies where the keys are movie titles and\n",
      "        the values are the difference between cumulative worldwide gross and budget.\n",
      "     Sort it by the difference descendingly.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(links.most_profitable.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.07 ms ± 237 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit links.most_profitable(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Avatar': 2686710708,\n",
       " 'Titanic': 2064812968,\n",
       " 'Star Wars: Episode VII - The Force Awakens': 1826310218,\n",
       " 'Avengers: Infinity War': 1731415039}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links.most_profitable(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        The method returns a dict with top-n movies where the keys are movie titles and\n",
      "        the values are their runtime. If there are more than one version – choose any.\n",
      "     Sort it by runtime descendingly.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(links.longest.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.46 ms ± 239 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit links.longest(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The Godfather Trilogy: 1901-1980': '9h 43m',\n",
       " 'Tie Xi Qu: West of the Tracks': '9h 11m',\n",
       " 'O.J.: Made in America': '7h 47m',\n",
       " 'The Best of Youth': '6h 14m',\n",
       " '1900': '5h 17m',\n",
       " 'As I Was Moving Ahead Occasionally I Saw Brief Glimpses of Beauty': '4h 48m',\n",
       " 'Until the End of the World': '4h 47m'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links.longest(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top_cost_per_minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        The method returns a dict with top-n movies where the keys are movie titles and\n",
      "the values are the budgets divided by their runtime. The budgets can be in different currencies – do not pay attention to it. \n",
      "     The values should be rounded to 2 decimals. Sort it by the division descendingly.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(links.top_cost_per_minute.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.51 ms ± 188 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit links.top_cost_per_minute(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The Name of the Rose': 230769230.77,\n",
       " 'Life Is Beautiful': 129310344.83,\n",
       " 'Train to Busan': 84745762.71,\n",
       " 'The Handmaiden': 68965517.24,\n",
       " 'Lupin III: The Castle of Cagliostro': 49019607.84,\n",
       " 'Lady Vengeance': 36521739.13,\n",
       " 'The Tale of The Princess Kaguya': 36496350.36,\n",
       " 'Ghost in the Shell 2: Innocence': 20000000.0,\n",
       " 'Princess Mononoke': 18045112.78,\n",
       " 'The Leopard': 15591397.85}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links.top_cost_per_minute(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Запуск тестов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.13.0, pytest-8.3.5, pluggy-1.5.0 -- C:\\Users\\ruber\\OneDrive\\Рабочий стол\\школа21\\DS_Bootcamp.Team00-1\\src\\urr\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: c:\\Users\\ruber\\OneDrive\\Рабочий стол\\школа21\\DS_Bootcamp.Team00-1\\src\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 27 items\n",
      "\n",
      "movielens_analysis.py::TestRatings::test_init \u001b[32mPASSED\u001b[0m\u001b[32m                     [  3%]\u001b[0m\n",
      "movielens_analysis.py::TestRatings::test_movies_init \u001b[32mPASSED\u001b[0m\u001b[32m              [  7%]\u001b[0m\n",
      "movielens_analysis.py::TestRatings::test_dist_by_year \u001b[32mPASSED\u001b[0m\u001b[32m             [ 11%]\u001b[0m\n",
      "movielens_analysis.py::TestRatings::test_dist_by_month \u001b[32mPASSED\u001b[0m\u001b[32m            [ 14%]\u001b[0m\n",
      "movielens_analysis.py::TestRatings::test_dist_by_rating \u001b[32mPASSED\u001b[0m\u001b[32m           [ 18%]\u001b[0m\n",
      "movielens_analysis.py::TestRatings::test_top_by_num_of_ratings \u001b[32mPASSED\u001b[0m\u001b[32m    [ 22%]\u001b[0m\n",
      "movielens_analysis.py::TestRatings::test_top_by_ratings \u001b[32mPASSED\u001b[0m\u001b[32m           [ 25%]\u001b[0m\n",
      "movielens_analysis.py::TestRatings::test_distribution_by_number \u001b[32mPASSED\u001b[0m\u001b[32m   [ 29%]\u001b[0m\n",
      "movielens_analysis.py::TestRatings::test_distribution_by_metric \u001b[32mPASSED\u001b[0m\u001b[32m   [ 33%]\u001b[0m\n",
      "movielens_analysis.py::TestRatings::test_top_by_variance \u001b[32mPASSED\u001b[0m\u001b[32m          [ 37%]\u001b[0m\n",
      "movielens_analysis.py::TestTags::test_most_words \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 40%]\u001b[0m\n",
      "movielens_analysis.py::TestTags::test_longest \u001b[32mPASSED\u001b[0m\u001b[32m                     [ 44%]\u001b[0m\n",
      "movielens_analysis.py::TestTags::test_most_words_and_longest \u001b[32mPASSED\u001b[0m\u001b[32m      [ 48%]\u001b[0m\n",
      "movielens_analysis.py::TestTags::test_most_popular \u001b[32mPASSED\u001b[0m\u001b[32m                [ 51%]\u001b[0m\n",
      "movielens_analysis.py::TestTags::test_tags_with \u001b[32mPASSED\u001b[0m\u001b[32m                   [ 55%]\u001b[0m\n",
      "movielens_analysis.py::TestMovies::test_dist_by_release \u001b[32mPASSED\u001b[0m\u001b[32m           [ 59%]\u001b[0m\n",
      "movielens_analysis.py::TestMovies::test_dist_by_genres \u001b[32mPASSED\u001b[0m\u001b[32m            [ 62%]\u001b[0m\n",
      "movielens_analysis.py::TestMovies::test_most_genres \u001b[32mPASSED\u001b[0m\u001b[32m               [ 66%]\u001b[0m\n",
      "movielens_analysis.py::TestMovies::test_movies_by_year \u001b[32mPASSED\u001b[0m\u001b[32m            [ 70%]\u001b[0m\n",
      "movielens_analysis.py::TestLinks::test_init \u001b[32mPASSED\u001b[0m\u001b[32m                       [ 74%]\u001b[0m\n",
      "movielens_analysis.py::TestLinks::test_init_parced \u001b[31mERROR\u001b[0m\u001b[31m                 [ 77%]\u001b[0m\n",
      "movielens_analysis.py::TestLinks::test_get_imdb \u001b[31mERROR\u001b[0m\u001b[31m                    [ 81%]\u001b[0m\n",
      "movielens_analysis.py::TestLinks::test_top_directors \u001b[31mERROR\u001b[0m\u001b[31m               [ 85%]\u001b[0m\n",
      "movielens_analysis.py::TestLinks::test_most_expensive \u001b[31mERROR\u001b[0m\u001b[31m              [ 88%]\u001b[0m\n",
      "movielens_analysis.py::TestLinks::test_most_profitable \u001b[31mERROR\u001b[0m\u001b[31m             [ 92%]\u001b[0m\n",
      "movielens_analysis.py::TestLinks::test_longest \u001b[31mERROR\u001b[0m\u001b[31m                     [ 96%]\u001b[0m\n",
      "movielens_analysis.py::TestLinks::test_top_cost_per_minute \u001b[31mERROR\u001b[0m\u001b[31m         [100%]\u001b[0m\n",
      "\n",
      "=================================== ERRORS ====================================\n",
      "\u001b[31m\u001b[1m________________ ERROR at setup of TestLinks.test_init_parced _________________\u001b[0m\n",
      "\n",
      "self = <movielens_analysis.TestLinks object at 0x000001D6DF16E120>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mmodule\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mlinks_parsed\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m Links(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata/links_parsed.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, parsed=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:800: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:221: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.data = CSVReader.csv_to_list_of_dicts(path_to_the_file,\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:58: in csv_to_list_of_dicts\n",
      "    \u001b[0mtext = file.read()\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <encodings.cp1251.IncrementalDecoder object at 0x000001D6DEFE4C30>\n",
      "input = b'movieId,imdbId,tmdbId,title,runtime,director,gross_worldwide,budget\\n1,0114709,862,\"Toy Story\",\"1h 21m\",\"John Lasset...d Apple\",\"1h 32m\",\"Takuya Igarashi\",2373203,None\\n193609,0101726,37891,\"Dice Rules\",\"1h 28m\",\"Jay Dubin\",637327,None\\n'\n",
      "final = True\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdecode\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, \u001b[96minput\u001b[39;49;00m, final=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m codecs.charmap_decode(\u001b[96minput\u001b[39;49;00m,\u001b[96mself\u001b[39;49;00m.errors,decoding_table)[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 564433: character maps to <undefined>\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\ruber\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\encodings\\cp1251.py\u001b[0m:23: UnicodeDecodeError\n",
      "\u001b[31m\u001b[1m__________________ ERROR at setup of TestLinks.test_get_imdb __________________\u001b[0m\n",
      "\n",
      "self = <movielens_analysis.TestLinks object at 0x000001D6DF16E120>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mmodule\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mlinks_parsed\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m Links(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata/links_parsed.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, parsed=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:800: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:221: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.data = CSVReader.csv_to_list_of_dicts(path_to_the_file,\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:58: in csv_to_list_of_dicts\n",
      "    \u001b[0mtext = file.read()\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <encodings.cp1251.IncrementalDecoder object at 0x000001D6DEFE4C30>\n",
      "input = b'movieId,imdbId,tmdbId,title,runtime,director,gross_worldwide,budget\\n1,0114709,862,\"Toy Story\",\"1h 21m\",\"John Lasset...d Apple\",\"1h 32m\",\"Takuya Igarashi\",2373203,None\\n193609,0101726,37891,\"Dice Rules\",\"1h 28m\",\"Jay Dubin\",637327,None\\n'\n",
      "final = True\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdecode\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, \u001b[96minput\u001b[39;49;00m, final=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m codecs.charmap_decode(\u001b[96minput\u001b[39;49;00m,\u001b[96mself\u001b[39;49;00m.errors,decoding_table)[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 564433: character maps to <undefined>\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\ruber\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\encodings\\cp1251.py\u001b[0m:23: UnicodeDecodeError\n",
      "\u001b[31m\u001b[1m_______________ ERROR at setup of TestLinks.test_top_directors ________________\u001b[0m\n",
      "\n",
      "self = <movielens_analysis.TestLinks object at 0x000001D6DF16E120>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mmodule\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mlinks_parsed\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m Links(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata/links_parsed.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, parsed=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:800: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:221: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.data = CSVReader.csv_to_list_of_dicts(path_to_the_file,\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:58: in csv_to_list_of_dicts\n",
      "    \u001b[0mtext = file.read()\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <encodings.cp1251.IncrementalDecoder object at 0x000001D6DEFE4C30>\n",
      "input = b'movieId,imdbId,tmdbId,title,runtime,director,gross_worldwide,budget\\n1,0114709,862,\"Toy Story\",\"1h 21m\",\"John Lasset...d Apple\",\"1h 32m\",\"Takuya Igarashi\",2373203,None\\n193609,0101726,37891,\"Dice Rules\",\"1h 28m\",\"Jay Dubin\",637327,None\\n'\n",
      "final = True\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdecode\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, \u001b[96minput\u001b[39;49;00m, final=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m codecs.charmap_decode(\u001b[96minput\u001b[39;49;00m,\u001b[96mself\u001b[39;49;00m.errors,decoding_table)[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 564433: character maps to <undefined>\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\ruber\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\encodings\\cp1251.py\u001b[0m:23: UnicodeDecodeError\n",
      "\u001b[31m\u001b[1m_______________ ERROR at setup of TestLinks.test_most_expensive _______________\u001b[0m\n",
      "\n",
      "self = <movielens_analysis.TestLinks object at 0x000001D6DF16E120>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mmodule\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mlinks_parsed\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m Links(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata/links_parsed.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, parsed=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:800: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:221: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.data = CSVReader.csv_to_list_of_dicts(path_to_the_file,\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:58: in csv_to_list_of_dicts\n",
      "    \u001b[0mtext = file.read()\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <encodings.cp1251.IncrementalDecoder object at 0x000001D6DEFE4C30>\n",
      "input = b'movieId,imdbId,tmdbId,title,runtime,director,gross_worldwide,budget\\n1,0114709,862,\"Toy Story\",\"1h 21m\",\"John Lasset...d Apple\",\"1h 32m\",\"Takuya Igarashi\",2373203,None\\n193609,0101726,37891,\"Dice Rules\",\"1h 28m\",\"Jay Dubin\",637327,None\\n'\n",
      "final = True\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdecode\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, \u001b[96minput\u001b[39;49;00m, final=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m codecs.charmap_decode(\u001b[96minput\u001b[39;49;00m,\u001b[96mself\u001b[39;49;00m.errors,decoding_table)[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 564433: character maps to <undefined>\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\ruber\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\encodings\\cp1251.py\u001b[0m:23: UnicodeDecodeError\n",
      "\u001b[31m\u001b[1m______________ ERROR at setup of TestLinks.test_most_profitable _______________\u001b[0m\n",
      "\n",
      "self = <movielens_analysis.TestLinks object at 0x000001D6DF16E120>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mmodule\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mlinks_parsed\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m Links(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata/links_parsed.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, parsed=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:800: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:221: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.data = CSVReader.csv_to_list_of_dicts(path_to_the_file,\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:58: in csv_to_list_of_dicts\n",
      "    \u001b[0mtext = file.read()\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <encodings.cp1251.IncrementalDecoder object at 0x000001D6DEFE4C30>\n",
      "input = b'movieId,imdbId,tmdbId,title,runtime,director,gross_worldwide,budget\\n1,0114709,862,\"Toy Story\",\"1h 21m\",\"John Lasset...d Apple\",\"1h 32m\",\"Takuya Igarashi\",2373203,None\\n193609,0101726,37891,\"Dice Rules\",\"1h 28m\",\"Jay Dubin\",637327,None\\n'\n",
      "final = True\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdecode\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, \u001b[96minput\u001b[39;49;00m, final=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m codecs.charmap_decode(\u001b[96minput\u001b[39;49;00m,\u001b[96mself\u001b[39;49;00m.errors,decoding_table)[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 564433: character maps to <undefined>\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\ruber\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\encodings\\cp1251.py\u001b[0m:23: UnicodeDecodeError\n",
      "\u001b[31m\u001b[1m__________________ ERROR at setup of TestLinks.test_longest ___________________\u001b[0m\n",
      "\n",
      "self = <movielens_analysis.TestLinks object at 0x000001D6DF16E120>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mmodule\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mlinks_parsed\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m Links(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata/links_parsed.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, parsed=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:800: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:221: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.data = CSVReader.csv_to_list_of_dicts(path_to_the_file,\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:58: in csv_to_list_of_dicts\n",
      "    \u001b[0mtext = file.read()\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <encodings.cp1251.IncrementalDecoder object at 0x000001D6DEFE4C30>\n",
      "input = b'movieId,imdbId,tmdbId,title,runtime,director,gross_worldwide,budget\\n1,0114709,862,\"Toy Story\",\"1h 21m\",\"John Lasset...d Apple\",\"1h 32m\",\"Takuya Igarashi\",2373203,None\\n193609,0101726,37891,\"Dice Rules\",\"1h 28m\",\"Jay Dubin\",637327,None\\n'\n",
      "final = True\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdecode\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, \u001b[96minput\u001b[39;49;00m, final=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m codecs.charmap_decode(\u001b[96minput\u001b[39;49;00m,\u001b[96mself\u001b[39;49;00m.errors,decoding_table)[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 564433: character maps to <undefined>\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\ruber\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\encodings\\cp1251.py\u001b[0m:23: UnicodeDecodeError\n",
      "\u001b[31m\u001b[1m____________ ERROR at setup of TestLinks.test_top_cost_per_minute _____________\u001b[0m\n",
      "\n",
      "self = <movielens_analysis.TestLinks object at 0x000001D6DF16E120>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.fixture(scope=\u001b[33m\"\u001b[39;49;00m\u001b[33mmodule\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mlinks_parsed\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m Links(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata/links_parsed.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, parsed=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:800: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:221: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.data = CSVReader.csv_to_list_of_dicts(path_to_the_file,\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mmovielens_analysis.py\u001b[0m:58: in csv_to_list_of_dicts\n",
      "    \u001b[0mtext = file.read()\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <encodings.cp1251.IncrementalDecoder object at 0x000001D6DEFE4C30>\n",
      "input = b'movieId,imdbId,tmdbId,title,runtime,director,gross_worldwide,budget\\n1,0114709,862,\"Toy Story\",\"1h 21m\",\"John Lasset...d Apple\",\"1h 32m\",\"Takuya Igarashi\",2373203,None\\n193609,0101726,37891,\"Dice Rules\",\"1h 28m\",\"Jay Dubin\",637327,None\\n'\n",
      "final = True\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mdecode\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, \u001b[96minput\u001b[39;49;00m, final=\u001b[94mFalse\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m codecs.charmap_decode(\u001b[96minput\u001b[39;49;00m,\u001b[96mself\u001b[39;49;00m.errors,decoding_table)[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 564433: character maps to <undefined>\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\ruber\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\encodings\\cp1251.py\u001b[0m:23: UnicodeDecodeError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n",
      "\u001b[31mERROR\u001b[0m movielens_analysis.py::\u001b[1mTestLinks::test_init_parced\u001b[0m - UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 5644...\n",
      "\u001b[31mERROR\u001b[0m movielens_analysis.py::\u001b[1mTestLinks::test_get_imdb\u001b[0m - UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 5644...\n",
      "\u001b[31mERROR\u001b[0m movielens_analysis.py::\u001b[1mTestLinks::test_top_directors\u001b[0m - UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 5644...\n",
      "\u001b[31mERROR\u001b[0m movielens_analysis.py::\u001b[1mTestLinks::test_most_expensive\u001b[0m - UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 5644...\n",
      "\u001b[31mERROR\u001b[0m movielens_analysis.py::\u001b[1mTestLinks::test_most_profitable\u001b[0m - UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 5644...\n",
      "\u001b[31mERROR\u001b[0m movielens_analysis.py::\u001b[1mTestLinks::test_longest\u001b[0m - UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 5644...\n",
      "\u001b[31mERROR\u001b[0m movielens_analysis.py::\u001b[1mTestLinks::test_top_cost_per_minute\u001b[0m - UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 5644...\n",
      "\u001b[31m======================== \u001b[32m20 passed\u001b[0m, \u001b[31m\u001b[1m7 errors\u001b[0m\u001b[31m in 7.90s\u001b[0m\u001b[31m =========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest -v movielens_analysis.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
